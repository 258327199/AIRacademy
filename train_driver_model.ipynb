{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "CODE_DIR = '/home/shreyas/Documents/git/wheelai/'\n",
    "traindata_path = '/media/shreyas/DATA/ML_DATA/wheelai/gtaV/sample_train/'\n",
    "validdata_path = '/media/shreyas/DATA/ML_DATA/wheelai/gtaV/valid/'\n",
    "results_path = '/media/shreyas/DATA/ML_DATA/wheelai/gtaV/results/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from __future__ import division, print_function\n",
    "\n",
    "import os, json\n",
    "from glob import glob\n",
    "import numpy as np\n",
    "from scipy import misc, ndimage\n",
    "from scipy.ndimage.interpolation import zoom\n",
    "\n",
    "import keras\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras import backend as K\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.models import Sequential, load_model,  Model\n",
    "from keras.layers.core import Flatten, Dense, Dropout, Lambda\n",
    "from keras.layers.convolutional import Conv2D, MaxPooling2D, ZeroPadding2D\n",
    "from keras.layers.pooling import GlobalAveragePooling2D\n",
    "from keras.optimizers import Adam, SGD\n",
    "from keras.preprocessing import image\n",
    "from keras.applications import VGG16\n",
    "from keras.layers import Input, Lambda, Cropping2D, Activation, ELU\n",
    "from keras.layers.merge import add, concatenate\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Finetune and Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "image_dims = (160,320)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_batches(path, class_mode='categorical', gen=image.ImageDataGenerator(), \\\n",
    "                shuffle=True, target_size=image_dims, batch_size=1):\n",
    "    return gen.flow_from_directory(path, class_mode=class_mode, batch_size=batch_size, \\\n",
    "                                   target_size=target_size, shuffle=shuffle)\n",
    "\n",
    "def get_steps(batches, batch_size):\n",
    "    steps = int(batches.samples/batch_size)\n",
    "    return (steps if batches.samples%batch_size==0 else (steps+1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 12954 images belonging to 3 classes.\n",
      "Found 3375 images belonging to 3 classes.\n"
     ]
    }
   ],
   "source": [
    "train_b = get_batches(traindata_path, batch_size=batch_size)\n",
    "valid_b = get_batches(validdata_path, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_steps = get_steps(train_b, batch_size)\n",
    "valid_steps = get_steps(valid_b, batch_size)\n",
    "num_class = train_b.num_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_labels = train_b.classes\n",
    "valid_labels = valid_b.classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_train = keras.utils.to_categorical(train_labels)\n",
    "y_valid = keras.utils.to_categorical(valid_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(12954,) (3375,) (12954, 3) (3375, 3)\n"
     ]
    }
   ],
   "source": [
    "print(train_labels.shape, valid_labels.shape, y_train.shape, y_valid.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 12954 images belonging to 3 classes.\n",
      "Found 3375 images belonging to 3 classes.\n"
     ]
    }
   ],
   "source": [
    "trn_b = get_batches(traindata_path, class_mode=None, shuffle=False, batch_size=batch_size)\n",
    "val_b = get_batches(validdata_path, class_mode=None, shuffle=False, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 12954 images belonging to 3 classes.\n"
     ]
    }
   ],
   "source": [
    "gen_augdata = image.ImageDataGenerator(width_shift_range=.2, height_shift_range=.2, \n",
    "                                      shear_range=0.2, zoom_range=0.2)\n",
    "augtrain_b = get_batches(traindata_path, gen=gen_augdata, class_mode='categorical',\\\n",
    "                         batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def nvidia_model():\n",
    "    x = Input(shape=(160, 320, 3))\n",
    "    crop_im = Cropping2D(cropping=((70,0), (0,0)))(x)\n",
    "    \n",
    "    color_s = Conv2D(3, (1,1), padding='same')(crop_im)\n",
    "    norm = Lambda(lambda x: (x / 255.0) - 0.5)(color_s)\n",
    "    \n",
    "    conv_b1 = Conv2D(24, (3,3), padding='same', activation='relu')(norm)\n",
    "    batch_1 = BatchNormalization()(conv_b1)\n",
    "    max_pl1 = MaxPooling2D()(batch_1)\n",
    "    \n",
    "    conv_b2 = Conv2D(36, (3,3), padding='same', activation='relu')(max_pl1)\n",
    "    batch_2 = BatchNormalization()(conv_b2)\n",
    "    max_pl2 = MaxPooling2D()(batch_2)\n",
    "    \n",
    "    conv_b3 = Conv2D(48, (3,3), padding='same', activation='relu')(max_pl2)\n",
    "    batch_3 = BatchNormalization()(conv_b3)\n",
    "    max_pl3 = MaxPooling2D()(batch_3)\n",
    "    \n",
    "    conv_b4 = Conv2D(64, (3,3), padding='same', activation='relu')(max_pl3)\n",
    "    batch_4 = BatchNormalization()(conv_b4)\n",
    "    max_pl4 = MaxPooling2D()(batch_4)\n",
    "    dropout = Dropout(0.1)(max_pl4)\n",
    "    \n",
    "    conv_b5 = Conv2D(64, (3,3), padding='same', activation='relu')(dropout)\n",
    "    batch_5 = BatchNormalization()(conv_b5)\n",
    "    max_pl5 = MaxPooling2D((1,4))(batch_5)\n",
    "    dropout = Dropout(0.1)(max_pl5)\n",
    "    \n",
    "    flatten = Flatten()(dropout)\n",
    "    fc1 = Dense(100, activation='relu')(flatten)\n",
    "    batch_fc1 = BatchNormalization()(fc1)\n",
    "    drop_fc1 = Dropout(0.2)(batch_fc1)\n",
    "    \n",
    "    fc2 = Dense(50, activation='relu')(drop_fc1)\n",
    "    batch_fc2 = BatchNormalization()(fc2)\n",
    "    drop_fc2 = Dropout(0.3)(batch_fc2)\n",
    "    \n",
    "    fc3 = Dense(10, activation='relu')(drop_fc2)\n",
    "    batch_fc3 = BatchNormalization()(fc3)\n",
    "    drop_fc3 = Dropout(0.5)(batch_fc3)\n",
    "    \n",
    "    output = Dense(3, activation='softmax')(drop_fc3)\n",
    "    \n",
    "    model = Model(inputs=x, outputs=output)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def nvidia_conv():\n",
    "    model = Sequential()\n",
    "    model.add(Cropping2D(cropping=((70,0), (0,0)), input_shape=(160, 320, 3)))\n",
    "    model.add(Lambda(lambda x: (x / 255.0) - 0.5))\n",
    "    model.add(Conv2D(3, (1,1), padding='same')) \n",
    "    model.add(Conv2D(24, (3,3), padding='same', activation='relu'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(MaxPooling2D())\n",
    "    model.add(Conv2D(36, (3,3), padding='same', activation='relu'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(MaxPooling2D())   \n",
    "    model.add(Conv2D(48, (3,3), padding='same', activation='relu'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(MaxPooling2D())\n",
    "    model.add(Conv2D(64, (3,3), padding='same', activation='relu'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(MaxPooling2D())\n",
    "    model.add(Conv2D(128, (3,3), padding='same', activation='relu'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(MaxPooling2D((1,4)))\n",
    "    model.add(Conv2D(3, (3,3), padding='same'))\n",
    "    model.add(GlobalAveragePooling2D())\n",
    "    model.add(Activation('softmax'))\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def base_model():\n",
    "    model = Sequential()\n",
    "    model.add(Cropping2D(cropping=((70,0), (0,0)), input_shape=(160, 320, 3)))\n",
    "    model.add(Lambda(lambda x: (x / 255.0) - 0.5))\n",
    "    model.add(Conv2D(3, (1,1), padding='same')) \n",
    "    model.add(Conv2D(32, (3,3), padding='same', activation='relu'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(MaxPooling2D())\n",
    "    model.add(Dropout(0.1))\n",
    "    model.add(Conv2D(64, (3,3), padding='same', activation='relu'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(MaxPooling2D())\n",
    "    model.add(Dropout(0.1))\n",
    "    model.add(Conv2D(128, (3,3), padding='same', activation='relu'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(MaxPooling2D())\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Flatten())    \n",
    "    model.add(Dense(256, activation='relu'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dropout(0.3))\n",
    "    model.add(Dense(256, activation='relu'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(3, activation='softmax'))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def amazon_model():\n",
    "    x = Input(shape = (160, 320, 3))\n",
    "    crop = Cropping2D(cropping=((70,0), (0,0)), input_shape=(160, 320, 3))(x)\n",
    "    norm = Lambda(lambda x: (x / 255.0) - 0.5)(crop)\n",
    "    \n",
    "    prep = Conv2D(10, (1,1), padding='same', activation='elu')(norm)\n",
    "    prep = Conv2D(10, (1,1), padding='same', activation='elu')(prep)\n",
    "    prep = Conv2D(3, (1,1), padding='same', activation='elu')(prep)\n",
    "    \n",
    "    conv1 = Conv2D(16, (3,3), padding='same', activation='relu')(prep)\n",
    "    norm1 = BatchNormalization()(conv1)\n",
    "    conv1 = Conv2D(32, (1,1), padding='same', activation='relu')(norm1)\n",
    "    norm1 = BatchNormalization()(conv1)\n",
    "    conv1 = Conv2D(32, (1,1), padding='same', activation='relu')(norm1)\n",
    "    norm1 = BatchNormalization()(conv1)\n",
    "    conv1 = Conv2D(32, (3,3), padding='same', activation='relu')(norm1)\n",
    "    norm1 = BatchNormalization()(conv1)\n",
    "    max_1 = MaxPooling2D()(norm1)\n",
    "    \n",
    "    conv2 = Conv2D(32, (3,3), padding='same', activation='relu')(max_1)\n",
    "    norm2 = BatchNormalization()(conv2)\n",
    "    conv2 = Conv2D(48, (1,1), padding='same', activation='relu')(norm2)\n",
    "    norm2 = BatchNormalization()(conv2)\n",
    "    conv2 = Conv2D(48, (1,1), padding='same', activation='relu')(norm2)\n",
    "    norm2 = BatchNormalization()(conv2)\n",
    "    conv2 = Conv2D(48, (3,3), padding='same', activation='relu')(norm2)\n",
    "    norm2 = BatchNormalization()(conv2)\n",
    "    max_2 = MaxPooling2D()(norm2)\n",
    "    gavg1 = GlobalAveragePooling2D()(max_2)\n",
    "    \n",
    "    conv3 = Conv2D(48, (3,3), padding='same', activation='relu')(max_2)\n",
    "    norm3 = BatchNormalization()(conv3)\n",
    "    conv3 = Conv2D(64, (1,1), padding='same', activation='relu')(norm3)\n",
    "    norm3 = BatchNormalization()(conv3)\n",
    "    conv3 = Conv2D(64, (1,1), padding='same', activation='relu')(norm3)\n",
    "    norm3 = BatchNormalization()(conv3)\n",
    "    conv3 = Conv2D(64, (3,3), padding='same', activation='relu')(norm3)\n",
    "    norm3 = BatchNormalization()(conv3)\n",
    "    max_3 = MaxPooling2D()(norm3)\n",
    "    gavg2 = GlobalAveragePooling2D()(max_3)\n",
    "    \n",
    "    conv4 = Conv2D(64, (3,3), padding='same', activation='relu')(max_3)\n",
    "    norm4 = BatchNormalization()(conv4)\n",
    "    conv4 = Conv2D(128, (1,1), padding='same', activation='relu')(norm4)\n",
    "    norm4 = BatchNormalization()(conv4)\n",
    "    conv4 = Conv2D(128, (1,1), padding='same', activation='relu')(norm4)\n",
    "    norm4 = BatchNormalization()(conv4)\n",
    "    conv4 = Conv2D(128, (3,3), padding='same', activation='relu')(norm4)\n",
    "    norm4 = BatchNormalization()(conv4)\n",
    "    max_4 = MaxPooling2D()(norm4)\n",
    "    gavg3 = GlobalAveragePooling2D()(max_4)\n",
    "    \n",
    "    merged = concatenate([gavg1, gavg2, gavg3])\n",
    "    fc_1 = Dense(240, activation='relu')(merged)\n",
    "    norm = BatchNormalization()(fc_1)\n",
    "    dropout = Dropout(0.5)(norm)\n",
    "    fc_2 = Dense(120, activation='relu')(dropout)\n",
    "    norm = BatchNormalization()(fc_2)\n",
    "    dropout = Dropout(0.5)(norm)\n",
    "    outout = Dense(3, activation='softmax')(dropout)\n",
    "    \n",
    "    model = Model(inputs=x, outputs=outout)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1 Nvidia Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 160, 320, 3)       0         \n",
      "_________________________________________________________________\n",
      "cropping2d_1 (Cropping2D)    (None, 90, 320, 3)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 90, 320, 3)        12        \n",
      "_________________________________________________________________\n",
      "lambda_1 (Lambda)            (None, 90, 320, 3)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 90, 320, 24)       672       \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 90, 320, 24)       96        \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 45, 160, 24)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 45, 160, 36)       7812      \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 45, 160, 36)       144       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 22, 80, 36)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 22, 80, 48)        15600     \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 22, 80, 48)        192       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 11, 40, 48)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 11, 40, 64)        27712     \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch (None, 11, 40, 64)        256       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2 (None, 5, 20, 64)         0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 5, 20, 64)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_6 (Conv2D)            (None, 5, 20, 64)         36928     \n",
      "_________________________________________________________________\n",
      "batch_normalization_5 (Batch (None, 5, 20, 64)         256       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_5 (MaxPooling2 (None, 5, 5, 64)          0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 5, 5, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 1600)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 100)               160100    \n",
      "_________________________________________________________________\n",
      "batch_normalization_6 (Batch (None, 100)               400       \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 50)                5050      \n",
      "_________________________________________________________________\n",
      "batch_normalization_7 (Batch (None, 50)                200       \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 10)                510       \n",
      "_________________________________________________________________\n",
      "batch_normalization_8 (Batch (None, 10)                40        \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 10)                0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 3)                 33        \n",
      "=================================================================\n",
      "Total params: 256,013\n",
      "Trainable params: 255,221\n",
      "Non-trainable params: 792\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = nvidia_model()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "adam = Adam(lr=1e-4, beta_1=0.9, beta_2=0.999, epsilon=1e-08, decay=0.0)\n",
    "model.compile(optimizer=adam,loss='categorical_crossentropy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#filepath1 = results_path+'nvidia.h5'\n",
    "#checkpoint1 = ModelCheckpoint(filepath1, monitor='val_loss', verbose=1, save_best_only=False,\\\n",
    "#                             save_weights_only=True, mode='min', period=1)\n",
    "#callbacks1=[checkpoint1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "203/203 [==============================] - 174s - loss: 1.7997 - val_loss: 1.2216\n",
      "Epoch 2/2\n",
      "203/203 [==============================] - 167s - loss: 1.4813 - val_loss: 1.1355\n"
     ]
    }
   ],
   "source": [
    "model.fit_generator(train_b, steps_per_epoch=train_steps, epochs=2, verbose=1,\\\n",
    "                        validation_data=valid_b, validation_steps=valid_steps)\n",
    "\n",
    "model.save_weights(results_path+'nvidia(1e-4).h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "203/203 [==============================] - 174s - loss: 1.3393 - val_loss: 0.9874\n",
      "Epoch 2/3\n",
      "203/203 [==============================] - 168s - loss: 1.2671 - val_loss: 1.0061\n",
      "Epoch 3/3\n",
      "203/203 [==============================] - 167s - loss: 1.1828 - val_loss: 0.9705\n"
     ]
    }
   ],
   "source": [
    "model.optimizer.lr = 1e-5\n",
    "model.fit_generator(train_b, steps_per_epoch=train_steps, epochs=3, verbose=1,\\\n",
    "                        validation_data=valid_b, validation_steps=valid_steps)\n",
    "\n",
    "model.save_weights(results_path+'nvidia(1e-5).h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "203/203 [==============================] - 173s - loss: 1.1232 - val_loss: 0.9599\n"
     ]
    }
   ],
   "source": [
    "model.optimizer.lr = 1e-3\n",
    "model.fit_generator(train_b, steps_per_epoch=train_steps, epochs=1, verbose=1,\\\n",
    "                        validation_data=valid_b, validation_steps=valid_steps)\n",
    "\n",
    "model.save_weights(results_path+'nvidia(1e-3).h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#filepath2 = results_path+'nvidia_aug.h5'\n",
    "#checkpoint2 = ModelCheckpoint(filepath2, monitor='val_loss', verbose=1, save_best_only=False,\\\n",
    "#                             save_weights_only=True, mode='min', period=1)\n",
    "#callbacks2=[checkpoint2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "203/203 [==============================] - 227s - loss: 1.3644 - val_loss: 1.0323\n",
      "Epoch 2/3\n",
      "203/203 [==============================] - 226s - loss: 1.2811 - val_loss: 1.0373\n",
      "Epoch 3/3\n",
      "203/203 [==============================] - 217s - loss: 1.2287 - val_loss: 1.0467\n"
     ]
    }
   ],
   "source": [
    "model.optimizer.lr = 1e-4\n",
    "model.fit_generator(augtrain_b, steps_per_epoch=train_steps, epochs=3, verbose=1,\\\n",
    "                        validation_data=valid_b, validation_steps=valid_steps)\n",
    "\n",
    "model.save_weights(results_path+'nvidia_aug(1e-4).h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "203/203 [==============================] - 238s - loss: 1.1842 - val_loss: 1.0170\n",
      "Epoch 2/2\n",
      "203/203 [==============================] - 228s - loss: 1.1599 - val_loss: 1.0724\n"
     ]
    }
   ],
   "source": [
    "model.optimizer.lr = 1e-3\n",
    "model.fit_generator(augtrain_b, steps_per_epoch=train_steps, epochs=2, verbose=1,\\\n",
    "                        validation_data=valid_b, validation_steps=valid_steps)\n",
    "\n",
    "model.save_weights(results_path+'nvidia_aug(1e-3).h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "203/203 [==============================] - 234s - loss: 1.1302 - val_loss: 1.0188\n",
      "Epoch 2/2\n",
      "203/203 [==============================] - 225s - loss: 1.1092 - val_loss: 1.0169\n"
     ]
    }
   ],
   "source": [
    "model.optimizer.lr = 1e-5\n",
    "model.fit_generator(augtrain_b, steps_per_epoch=train_steps, epochs=2, verbose=1,\\\n",
    "                        validation_data=valid_b, validation_steps=valid_steps)\n",
    "\n",
    "model.save_weights(results_path+'nvidia_aug(1e-5).h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2 Nvidia All CONV model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "cropping2d_8 (Cropping2D)    (None, 90, 320, 3)        0         \n",
      "_________________________________________________________________\n",
      "lambda_8 (Lambda)            (None, 90, 320, 3)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_36 (Conv2D)           (None, 90, 320, 3)        12        \n",
      "_________________________________________________________________\n",
      "conv2d_37 (Conv2D)           (None, 90, 320, 24)       672       \n",
      "_________________________________________________________________\n",
      "batch_normalization_32 (Batc (None, 90, 320, 24)       96        \n",
      "_________________________________________________________________\n",
      "max_pooling2d_24 (MaxPooling (None, 45, 160, 24)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_38 (Conv2D)           (None, 45, 160, 36)       7812      \n",
      "_________________________________________________________________\n",
      "batch_normalization_33 (Batc (None, 45, 160, 36)       144       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_25 (MaxPooling (None, 22, 80, 36)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_39 (Conv2D)           (None, 22, 80, 48)        15600     \n",
      "_________________________________________________________________\n",
      "batch_normalization_34 (Batc (None, 22, 80, 48)        192       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_26 (MaxPooling (None, 11, 40, 48)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_40 (Conv2D)           (None, 11, 40, 64)        27712     \n",
      "_________________________________________________________________\n",
      "batch_normalization_35 (Batc (None, 11, 40, 64)        256       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_27 (MaxPooling (None, 5, 20, 64)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_41 (Conv2D)           (None, 5, 20, 128)        73856     \n",
      "_________________________________________________________________\n",
      "batch_normalization_36 (Batc (None, 5, 20, 128)        512       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_28 (MaxPooling (None, 5, 5, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_42 (Conv2D)           (None, 5, 5, 3)           3459      \n",
      "_________________________________________________________________\n",
      "global_average_pooling2d_4 ( (None, 3)                 0         \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 3)                 0         \n",
      "=================================================================\n",
      "Total params: 130,323\n",
      "Trainable params: 129,723\n",
      "Non-trainable params: 600\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = nvidia_conv()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "adam = Adam(lr=1e-4, beta_1=0.9, beta_2=0.999, epsilon=1e-08, decay=0.0)\n",
    "model.compile(optimizer=adam,loss='categorical_crossentropy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "203/203 [==============================] - 172s - loss: 1.0049 - val_loss: 1.1923\n",
      "Epoch 2/2\n",
      "203/203 [==============================] - 164s - loss: 0.8197 - val_loss: 1.3432\n"
     ]
    }
   ],
   "source": [
    "model.fit_generator(train_b, steps_per_epoch=train_steps, epochs=2, verbose=1,\\\n",
    "                        validation_data=valid_b, validation_steps=valid_steps)\n",
    "\n",
    "model.save_weights(results_path+'nvidia_conv(1e-4).h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "203/203 [==============================] - 172s - loss: 0.7454 - val_loss: 0.9915\n",
      "Epoch 2/3\n",
      "203/203 [==============================] - 166s - loss: 0.6958 - val_loss: 0.8565\n",
      "Epoch 3/3\n",
      "203/203 [==============================] - 165s - loss: 0.6637 - val_loss: 0.9553\n"
     ]
    }
   ],
   "source": [
    "model.optimizer.lr = 1e-5\n",
    "model.fit_generator(train_b, steps_per_epoch=train_steps, epochs=3, verbose=1,\\\n",
    "                        validation_data=valid_b, validation_steps=valid_steps)\n",
    "\n",
    "model.save_weights(results_path+'nvidia_conv(1e-5).h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "203/203 [==============================] - 171s - loss: 0.6396 - val_loss: 0.8525\n"
     ]
    }
   ],
   "source": [
    "model.optimizer.lr = 1e-3\n",
    "model.fit_generator(train_b, steps_per_epoch=train_steps, epochs=1, verbose=1,\\\n",
    "                        validation_data=valid_b, validation_steps=valid_steps)\n",
    "\n",
    "model.save_weights(results_path+'nvidia_conv(1e-3).h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#filepath2 = results_path+'nvidia_aug.h5'\n",
    "#checkpoint2 = ModelCheckpoint(filepath2, monitor='val_loss', verbose=1, save_best_only=False,\\\n",
    "#                             save_weights_only=True, mode='min', period=1)\n",
    "#callbacks2=[checkpoint2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "203/203 [==============================] - 226s - loss: 0.9572 - val_loss: 0.9619\n",
      "Epoch 2/3\n",
      "203/203 [==============================] - 217s - loss: 0.9010 - val_loss: 1.0469\n",
      "Epoch 3/3\n",
      "203/203 [==============================] - 217s - loss: 0.9013 - val_loss: 1.0190\n"
     ]
    }
   ],
   "source": [
    "model.optimizer.lr = 1e-4\n",
    "model.fit_generator(augtrain_b, steps_per_epoch=train_steps, epochs=3, verbose=1,\\\n",
    "                        validation_data=valid_b, validation_steps=valid_steps)\n",
    "\n",
    "model.save_weights(results_path+'nvidia_conv_aug(1e-4).h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "203/203 [==============================] - 225s - loss: 0.8762 - val_loss: 0.9665\n",
      "Epoch 2/2\n",
      "203/203 [==============================] - 216s - loss: 0.8772 - val_loss: 0.9583\n"
     ]
    }
   ],
   "source": [
    "model.optimizer.lr = 1e-3\n",
    "model.fit_generator(augtrain_b, steps_per_epoch=train_steps, epochs=2, verbose=1,\\\n",
    "                        validation_data=valid_b, validation_steps=valid_steps)\n",
    "\n",
    "model.save_weights(results_path+'nvidia_conv_aug(1e-3).h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "203/203 [==============================] - 226s - loss: 0.8612 - val_loss: 1.0659\n",
      "Epoch 2/2\n",
      "203/203 [==============================] - 216s - loss: 0.8528 - val_loss: 1.0240\n"
     ]
    }
   ],
   "source": [
    "model.optimizer.lr = 1e-5\n",
    "model.fit_generator(augtrain_b, steps_per_epoch=train_steps, epochs=2, verbose=1,\\\n",
    "                        validation_data=valid_b, validation_steps=valid_steps)\n",
    "\n",
    "model.save_weights(results_path+'nvidia_conv_aug(1e-5).h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3 Amazon Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "input_6 (InputLayer)             (None, 160, 320, 3)   0                                            \n",
      "____________________________________________________________________________________________________\n",
      "cropping2d_12 (Cropping2D)       (None, 90, 320, 3)    0                                            \n",
      "____________________________________________________________________________________________________\n",
      "lambda_12 (Lambda)               (None, 90, 320, 3)    0                                            \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_100 (Conv2D)              (None, 90, 320, 10)   40                                           \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_101 (Conv2D)              (None, 90, 320, 10)   110                                          \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_102 (Conv2D)              (None, 90, 320, 3)    33                                           \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_103 (Conv2D)              (None, 90, 320, 16)   448                                          \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_87 (BatchNor (None, 90, 320, 16)   64                                           \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_104 (Conv2D)              (None, 90, 320, 32)   544                                          \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_88 (BatchNor (None, 90, 320, 32)   128                                          \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_105 (Conv2D)              (None, 90, 320, 32)   1056                                         \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_89 (BatchNor (None, 90, 320, 32)   128                                          \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_106 (Conv2D)              (None, 90, 320, 32)   9248                                         \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_90 (BatchNor (None, 90, 320, 32)   128                                          \n",
      "____________________________________________________________________________________________________\n",
      "max_pooling2d_41 (MaxPooling2D)  (None, 45, 160, 32)   0                                            \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_107 (Conv2D)              (None, 45, 160, 32)   9248                                         \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_91 (BatchNor (None, 45, 160, 32)   128                                          \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_108 (Conv2D)              (None, 45, 160, 48)   1584                                         \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_92 (BatchNor (None, 45, 160, 48)   192                                          \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_109 (Conv2D)              (None, 45, 160, 48)   2352                                         \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_93 (BatchNor (None, 45, 160, 48)   192                                          \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_110 (Conv2D)              (None, 45, 160, 48)   20784                                        \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_94 (BatchNor (None, 45, 160, 48)   192                                          \n",
      "____________________________________________________________________________________________________\n",
      "max_pooling2d_42 (MaxPooling2D)  (None, 22, 80, 48)    0                                            \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_111 (Conv2D)              (None, 22, 80, 48)    20784                                        \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_95 (BatchNor (None, 22, 80, 48)    192                                          \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_112 (Conv2D)              (None, 22, 80, 64)    3136                                         \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_96 (BatchNor (None, 22, 80, 64)    256                                          \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_113 (Conv2D)              (None, 22, 80, 64)    4160                                         \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_97 (BatchNor (None, 22, 80, 64)    256                                          \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_114 (Conv2D)              (None, 22, 80, 64)    36928                                        \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_98 (BatchNor (None, 22, 80, 64)    256                                          \n",
      "____________________________________________________________________________________________________\n",
      "max_pooling2d_43 (MaxPooling2D)  (None, 11, 40, 64)    0                                            \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_115 (Conv2D)              (None, 11, 40, 64)    36928                                        \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_99 (BatchNor (None, 11, 40, 64)    256                                          \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_116 (Conv2D)              (None, 11, 40, 128)   8320                                         \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_100 (BatchNo (None, 11, 40, 128)   512                                          \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_117 (Conv2D)              (None, 11, 40, 128)   16512                                        \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_101 (BatchNo (None, 11, 40, 128)   512                                          \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_118 (Conv2D)              (None, 11, 40, 128)   147584                                       \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_102 (BatchNo (None, 11, 40, 128)   512                                          \n",
      "____________________________________________________________________________________________________\n",
      "max_pooling2d_44 (MaxPooling2D)  (None, 5, 20, 128)    0                                            \n",
      "____________________________________________________________________________________________________\n",
      "global_average_pooling2d_14 (Glo (None, 48)            0                                            \n",
      "____________________________________________________________________________________________________\n",
      "global_average_pooling2d_15 (Glo (None, 64)            0                                            \n",
      "____________________________________________________________________________________________________\n",
      "global_average_pooling2d_16 (Glo (None, 128)           0                                            \n",
      "____________________________________________________________________________________________________\n",
      "concatenate_4 (Concatenate)      (None, 240)           0                                            \n",
      "____________________________________________________________________________________________________\n",
      "dense_11 (Dense)                 (None, 240)           57840                                        \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_103 (BatchNo (None, 240)           960                                          \n",
      "____________________________________________________________________________________________________\n",
      "dropout_13 (Dropout)             (None, 240)           0                                            \n",
      "____________________________________________________________________________________________________\n",
      "dense_12 (Dense)                 (None, 120)           28920                                        \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_104 (BatchNo (None, 120)           480                                          \n",
      "____________________________________________________________________________________________________\n",
      "dropout_14 (Dropout)             (None, 120)           0                                            \n",
      "____________________________________________________________________________________________________\n",
      "dense_13 (Dense)                 (None, 3)             363                                          \n",
      "====================================================================================================\n",
      "Total params: 412,266\n",
      "Trainable params: 409,594\n",
      "Non-trainable params: 2,672\n",
      "____________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = amazon_model()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "adam = Adam(lr=1e-4, beta_1=0.9, beta_2=0.999, epsilon=1e-08, decay=0.0)\n",
    "model.compile(optimizer=adam,loss='categorical_crossentropy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "203/203 [==============================] - 304s - loss: 1.7531 - val_loss: 1.1207\n",
      "Epoch 2/2\n",
      "203/203 [==============================] - 303s - loss: 1.5971 - val_loss: 1.4024\n"
     ]
    }
   ],
   "source": [
    "model.fit_generator(train_b, steps_per_epoch=train_steps, epochs=2, verbose=1,\\\n",
    "                        validation_data=valid_b, validation_steps=valid_steps)\n",
    "\n",
    "model.save_weights(results_path+'amazon(1e-4).h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "203/203 [==============================] - 306s - loss: 1.5257 - val_loss: 1.1276\n",
      "Epoch 2/3\n",
      "203/203 [==============================] - 305s - loss: 1.4689 - val_loss: 1.1711\n",
      "Epoch 3/3\n",
      "203/203 [==============================] - 303s - loss: 1.4199 - val_loss: 1.1248\n"
     ]
    }
   ],
   "source": [
    "model.optimizer.lr = 1e-5\n",
    "model.fit_generator(train_b, steps_per_epoch=train_steps, epochs=3, verbose=1,\\\n",
    "                        validation_data=valid_b, validation_steps=valid_steps)\n",
    "\n",
    "model.save_weights(results_path+'amazon(1e-5).h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "203/203 [==============================] - 303s - loss: 1.3843 - val_loss: 1.1659\n"
     ]
    }
   ],
   "source": [
    "model.optimizer.lr = 1e-3\n",
    "model.fit_generator(train_b, steps_per_epoch=train_steps, epochs=1, verbose=1,\\\n",
    "                        validation_data=valid_b, validation_steps=valid_steps)\n",
    "\n",
    "model.save_weights(results_path+'amazon(1e-3).h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#filepath2 = results_path+'nvidia_aug.h5'\n",
    "#checkpoint2 = ModelCheckpoint(filepath2, monitor='val_loss', verbose=1, save_best_only=False,\\\n",
    "#                             save_weights_only=True, mode='min', period=1)\n",
    "#callbacks2=[checkpoint2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "203/203 [==============================] - 303s - loss: 1.3432 - val_loss: 1.1212\n",
      "Epoch 2/3\n",
      "203/203 [==============================] - 303s - loss: 1.3103 - val_loss: 1.2252\n",
      "Epoch 3/3\n",
      "203/203 [==============================] - 302s - loss: 1.2807 - val_loss: 1.2489\n"
     ]
    }
   ],
   "source": [
    "model.optimizer.lr = 1e-4\n",
    "model.fit_generator(augtrain_b, steps_per_epoch=train_steps, epochs=3, verbose=1,\\\n",
    "                        validation_data=valid_b, validation_steps=valid_steps)\n",
    "\n",
    "model.save_weights(results_path+'amazon_aug(1e-4).h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "203/203 [==============================] - 306s - loss: 1.2456 - val_loss: 1.7032\n",
      "Epoch 2/2\n",
      "203/203 [==============================] - 308s - loss: 1.2525 - val_loss: 1.1948\n"
     ]
    }
   ],
   "source": [
    "model.optimizer.lr = 1e-3\n",
    "model.fit_generator(augtrain_b, steps_per_epoch=train_steps, epochs=2, verbose=1,\\\n",
    "                        validation_data=valid_b, validation_steps=valid_steps)\n",
    "\n",
    "model.save_weights(results_path+'amazon_aug(1e-3).h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "203/203 [==============================] - 303s - loss: 1.2140 - val_loss: 1.1525\n",
      "Epoch 2/2\n",
      "203/203 [==============================] - 304s - loss: 1.2020 - val_loss: 1.1098\n"
     ]
    }
   ],
   "source": [
    "model.optimizer.lr = 1e-5\n",
    "model.fit_generator(augtrain_b, steps_per_epoch=train_steps, epochs=2, verbose=1,\\\n",
    "                        validation_data=valid_b, validation_steps=valid_steps)\n",
    "\n",
    "model.save_weights(results_path+'amazon_aug(1e-5).h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4 Base Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "cropping2d_7 (Cropping2D)    (None, 90, 320, 3)        0         \n",
      "_________________________________________________________________\n",
      "lambda_7 (Lambda)            (None, 90, 320, 3)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_32 (Conv2D)           (None, 90, 320, 3)        12        \n",
      "_________________________________________________________________\n",
      "conv2d_33 (Conv2D)           (None, 90, 320, 32)       896       \n",
      "_________________________________________________________________\n",
      "batch_normalization_27 (Batc (None, 90, 320, 32)       128       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_21 (MaxPooling (None, 45, 160, 32)       0         \n",
      "_________________________________________________________________\n",
      "dropout_6 (Dropout)          (None, 45, 160, 32)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_34 (Conv2D)           (None, 45, 160, 64)       18496     \n",
      "_________________________________________________________________\n",
      "batch_normalization_28 (Batc (None, 45, 160, 64)       256       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_22 (MaxPooling (None, 22, 80, 64)        0         \n",
      "_________________________________________________________________\n",
      "dropout_7 (Dropout)          (None, 22, 80, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_35 (Conv2D)           (None, 22, 80, 128)       73856     \n",
      "_________________________________________________________________\n",
      "batch_normalization_29 (Batc (None, 22, 80, 128)       512       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_23 (MaxPooling (None, 11, 40, 128)       0         \n",
      "_________________________________________________________________\n",
      "dropout_8 (Dropout)          (None, 11, 40, 128)       0         \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 56320)             0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 256)               14418176  \n",
      "_________________________________________________________________\n",
      "batch_normalization_30 (Batc (None, 256)               1024      \n",
      "_________________________________________________________________\n",
      "dropout_9 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "batch_normalization_31 (Batc (None, 256)               1024      \n",
      "_________________________________________________________________\n",
      "dropout_10 (Dropout)         (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 3)                 771       \n",
      "=================================================================\n",
      "Total params: 14,580,943\n",
      "Trainable params: 14,579,471\n",
      "Non-trainable params: 1,472\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = base_model()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "adam = Adam(lr=1e-4, beta_1=0.9, beta_2=0.999, epsilon=1e-08, decay=0.0)\n",
    "model.compile(optimizer=adam,loss='categorical_crossentropy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "203/203 [==============================] - 177s - loss: 1.3846 - val_loss: 2.1978\n",
      "Epoch 2/2\n",
      "203/203 [==============================] - 164s - loss: 1.1824 - val_loss: 1.9703\n"
     ]
    }
   ],
   "source": [
    "model.fit_generator(train_b, steps_per_epoch=train_steps, epochs=2, verbose=1,\\\n",
    "                        validation_data=valid_b, validation_steps=valid_steps)\n",
    "\n",
    "model.save_weights(results_path+'base(1e-4).h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "203/203 [==============================] - 171s - loss: 1.0318 - val_loss: 1.0129\n",
      "Epoch 2/3\n",
      "203/203 [==============================] - 165s - loss: 0.9224 - val_loss: 0.8906\n",
      "Epoch 3/3\n",
      "203/203 [==============================] - 165s - loss: 0.7950 - val_loss: 0.9065\n"
     ]
    }
   ],
   "source": [
    "model.optimizer.lr = 1e-5\n",
    "model.fit_generator(train_b, steps_per_epoch=train_steps, epochs=3, verbose=1,\\\n",
    "                        validation_data=valid_b, validation_steps=valid_steps)\n",
    "\n",
    "model.save_weights(results_path+'base(1e-5).h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "203/203 [==============================] - 170s - loss: 0.7074 - val_loss: 0.9304\n"
     ]
    }
   ],
   "source": [
    "model.optimizer.lr = 1e-3\n",
    "model.fit_generator(train_b, steps_per_epoch=train_steps, epochs=1, verbose=1,\\\n",
    "                        validation_data=valid_b, validation_steps=valid_steps)\n",
    "\n",
    "model.save_weights(results_path+'base(1e-3).h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#filepath2 = results_path+'nvidia_aug.h5'\n",
    "#checkpoint2 = ModelCheckpoint(filepath2, monitor='val_loss', verbose=1, save_best_only=False,\\\n",
    "#                             save_weights_only=True, mode='min', period=1)\n",
    "#callbacks2=[checkpoint2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "203/203 [==============================] - 227s - loss: 1.3445 - val_loss: 1.5227\n",
      "Epoch 2/3\n",
      "203/203 [==============================] - 217s - loss: 1.2114 - val_loss: 1.2137\n",
      "Epoch 3/3\n",
      "203/203 [==============================] - 216s - loss: 1.1757 - val_loss: 1.0981\n"
     ]
    }
   ],
   "source": [
    "model.optimizer.lr = 1e-4\n",
    "model.fit_generator(augtrain_b, steps_per_epoch=train_steps, epochs=3, verbose=1,\\\n",
    "                        validation_data=valid_b, validation_steps=valid_steps)\n",
    "\n",
    "model.save_weights(results_path+'base_aug(1e-4).h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "203/203 [==============================] - 225s - loss: 1.1086 - val_loss: 1.0019\n",
      "Epoch 2/2\n",
      "203/203 [==============================] - 217s - loss: 1.0737 - val_loss: 1.0344\n"
     ]
    }
   ],
   "source": [
    "model.optimizer.lr = 1e-3\n",
    "model.fit_generator(augtrain_b, steps_per_epoch=train_steps, epochs=2, verbose=1,\\\n",
    "                        validation_data=valid_b, validation_steps=valid_steps)\n",
    "\n",
    "model.save_weights(results_path+'base_aug(1e-3).h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "203/203 [==============================] - 226s - loss: 1.0273 - val_loss: 1.0051\n",
      "Epoch 2/2\n",
      "203/203 [==============================] - 218s - loss: 1.0255 - val_loss: 1.0045\n"
     ]
    }
   ],
   "source": [
    "model.optimizer.lr = 1e-5\n",
    "model.fit_generator(augtrain_b, steps_per_epoch=train_steps, epochs=2, verbose=1,\\\n",
    "                        validation_data=valid_b, validation_steps=valid_steps)\n",
    "\n",
    "model.save_weights(results_path+'base_aug(1e-5).h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#serialize model to JSON\n",
    "model_path = results_path+'nvidia.json'\n",
    "model_json = model.to_json()\n",
    "with open(model_path, \"w\") as json_file:\n",
    "    json_file.write(model_json)\n",
    "#serialize weights to HDF5\n",
    "model.save_weights(filepath2)\n",
    "print(\"Saved model to disk\")"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
