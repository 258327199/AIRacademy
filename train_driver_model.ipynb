{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "CODE_DIR = '/home/shreyas/Documents/git/wheelai/'\n",
    "traindata_path = '/media/shreyas/DATA/ML_DATA/wheelai/gtaV/sample_train/'\n",
    "validdata_path = '/media/shreyas/DATA/ML_DATA/wheelai/gtaV/valid/'\n",
    "results_path = '/media/shreyas/DATA/ML_DATA/wheelai/gtaV/results/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from __future__ import division, print_function\n",
    "\n",
    "import os, json\n",
    "from glob import glob\n",
    "import numpy as np\n",
    "from scipy import misc, ndimage\n",
    "from scipy.ndimage.interpolation import zoom\n",
    "\n",
    "import keras\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras import backend as K\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.models import Sequential, load_model,  Model\n",
    "from keras.layers.core import Flatten, Dense, Dropout, Lambda\n",
    "from keras.layers.convolutional import Conv2D, MaxPooling2D, ZeroPadding2D\n",
    "from keras.layers.pooling import GlobalAveragePooling2D\n",
    "from keras.optimizers import Adam, SGD\n",
    "from keras.preprocessing import image\n",
    "from keras.applications import VGG16\n",
    "from keras.layers import Lambda, Cropping2D, Activation, ELU\n",
    "\n",
    "%matplotlib inline\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Finetune and Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "epochs = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_batches(path, class_mode='categorical', gen=image.ImageDataGenerator(), \\\n",
    "                shuffle=True, target_size=(160, 320), batch_size=1):\n",
    "    return gen.flow_from_directory(path, class_mode=class_mode, batch_size=batch_size, \\\n",
    "                                   target_size=target_size, shuffle=shuffle)\n",
    "\n",
    "def get_steps(batches, batch_size):\n",
    "    steps = int(batches.samples/batch_size)\n",
    "    return (steps if batches.samples%batch_size==0 else (steps+1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 12954 images belonging to 3 classes.\n",
      "Found 3375 images belonging to 3 classes.\n"
     ]
    }
   ],
   "source": [
    "train_b = get_batches(traindata_path, batch_size=batch_size)\n",
    "valid_b = get_batches(validdata_path, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_steps = get_steps(train_b, batch_size)\n",
    "valid_steps = get_steps(valid_b, batch_size)\n",
    "num_class = train_b.num_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_labels = train_b.classes\n",
    "valid_labels = valid_b.classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_train = keras.utils.to_categorical(train_labels)\n",
    "y_valid = keras.utils.to_categorical(valid_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(12954,) (3375,) (12954, 3) (3375, 3)\n"
     ]
    }
   ],
   "source": [
    "print(train_labels.shape, valid_labels.shape, y_train.shape, y_valid.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 12954 images belonging to 3 classes.\n",
      "Found 3375 images belonging to 3 classes.\n"
     ]
    }
   ],
   "source": [
    "trn_b = get_batches(traindata_path, class_mode=None, shuffle=False, batch_size=batch_size)\n",
    "val_b = get_batches(validdata_path, class_mode=None, shuffle=False, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 12954 images belonging to 3 classes.\n"
     ]
    }
   ],
   "source": [
    "gen_augdata = image.ImageDataGenerator(width_shift_range=.2, height_shift_range=.2, \n",
    "                                      shear_range=0.2, zoom_range=0.2)\n",
    "augtrain_b = get_batches(traindata_path, gen=gen_augdata, class_mode='categorical',\\\n",
    "                         batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#from keras.applications.resnet50 import ResNet50\n",
    "#from keras.preprocessing import image\n",
    "#from keras.applications.resnet50 import preprocess_input, decode_predictions\n",
    "\n",
    "#def resnet50():\n",
    "#    model = ResNet50(include_top = False, weights='imagenet', input_shape=(200, 400, 3))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "filter_size = 3\n",
    "pool_size = (2,2)\n",
    "\n",
    "\n",
    "def get_model():\n",
    "    model = Sequential()\n",
    "    model.add(Cropping2D(cropping=((70,0), (0,0)), input_shape=(160, 320, 3)))\n",
    "    model.add(Lambda(lambda x: x/255.-0.5))\n",
    "    model.add(Conv2D(3,1,1,\n",
    "                        border_mode='valid',\n",
    "                        name='conv0', init='he_normal'))\n",
    "    model.add(Conv2D(32,filter_size,filter_size,\n",
    "                        border_mode='valid',\n",
    "                        name='conv1', init='he_normal'))\n",
    "    model.add(ELU())\n",
    "    model.add(Conv2D(32,filter_size,filter_size,\n",
    "                        border_mode='valid',\n",
    "                        name='conv2', init='he_normal'))\n",
    "    model.add(ELU())\n",
    "    model.add(MaxPooling2D(pool_size=pool_size))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Conv2D(64,filter_size,filter_size,\n",
    "                        border_mode='valid',\n",
    "                        name='conv3', init='he_normal'))\n",
    "    model.add(ELU())\n",
    "\n",
    "    model.add(Conv2D(64,filter_size,filter_size,\n",
    "                        border_mode='valid',\n",
    "                        name='conv4', init='he_normal'))\n",
    "    model.add(ELU())\n",
    "    model.add(MaxPooling2D(pool_size=pool_size))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Conv2D(128,filter_size,filter_size,\n",
    "                        border_mode='valid',\n",
    "                        name='conv5', init='he_normal'))\n",
    "    model.add(ELU())\n",
    "    model.add(Conv2D(128,filter_size,filter_size,\n",
    "                        border_mode='valid',\n",
    "                        name='conv6', init='he_normal'))\n",
    "    model.add(ELU())\n",
    "    model.add(MaxPooling2D(pool_size=pool_size))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(512,name='hidden1', init='he_normal'))\n",
    "    model.add(ELU())\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(64,name='hidden2', init='he_normal'))\n",
    "    model.add(ELU())\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(16,name='hidden3',init='he_normal'))\n",
    "    model.add(ELU())\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(3, name='output', init='he_normal'))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/shreyas/anaconda3/envs/wheelai/lib/python3.5/site-packages/ipykernel/__main__.py:11: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(3, (1, 1), padding=\"valid\", name=\"conv0\", kernel_initializer=\"he_normal\")`\n",
      "/home/shreyas/anaconda3/envs/wheelai/lib/python3.5/site-packages/ipykernel/__main__.py:14: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(32, (3, 3), padding=\"valid\", name=\"conv1\", kernel_initializer=\"he_normal\")`\n",
      "/home/shreyas/anaconda3/envs/wheelai/lib/python3.5/site-packages/ipykernel/__main__.py:18: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(32, (3, 3), padding=\"valid\", name=\"conv2\", kernel_initializer=\"he_normal\")`\n",
      "/home/shreyas/anaconda3/envs/wheelai/lib/python3.5/site-packages/ipykernel/__main__.py:24: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(64, (3, 3), padding=\"valid\", name=\"conv3\", kernel_initializer=\"he_normal\")`\n",
      "/home/shreyas/anaconda3/envs/wheelai/lib/python3.5/site-packages/ipykernel/__main__.py:29: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(64, (3, 3), padding=\"valid\", name=\"conv4\", kernel_initializer=\"he_normal\")`\n",
      "/home/shreyas/anaconda3/envs/wheelai/lib/python3.5/site-packages/ipykernel/__main__.py:35: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(128, (3, 3), padding=\"valid\", name=\"conv5\", kernel_initializer=\"he_normal\")`\n",
      "/home/shreyas/anaconda3/envs/wheelai/lib/python3.5/site-packages/ipykernel/__main__.py:39: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(128, (3, 3), padding=\"valid\", name=\"conv6\", kernel_initializer=\"he_normal\")`\n",
      "/home/shreyas/anaconda3/envs/wheelai/lib/python3.5/site-packages/ipykernel/__main__.py:44: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(512, name=\"hidden1\", kernel_initializer=\"he_normal\")`\n",
      "/home/shreyas/anaconda3/envs/wheelai/lib/python3.5/site-packages/ipykernel/__main__.py:47: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(64, name=\"hidden2\", kernel_initializer=\"he_normal\")`\n",
      "/home/shreyas/anaconda3/envs/wheelai/lib/python3.5/site-packages/ipykernel/__main__.py:50: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(16, name=\"hidden3\", kernel_initializer=\"he_normal\")`\n",
      "/home/shreyas/anaconda3/envs/wheelai/lib/python3.5/site-packages/ipykernel/__main__.py:53: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(3, name=\"output\", kernel_initializer=\"he_normal\")`\n"
     ]
    }
   ],
   "source": [
    "model = get_model()\n",
    "adam = Adam(lr=1e-4, beta_1=0.9, beta_2=0.999, epsilon=1e-08, decay=0.0)\n",
    "model.compile(optimizer=adam,loss='categorical_crossentropy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "filepath1 = results_path+'nvidia.h5'\n",
    "checkpoint1 = ModelCheckpoint(filepath1, monitor='val_loss', verbose=1, save_best_only=False,\\\n",
    "                             save_weights_only=True, mode='min', period=1)\n",
    "callbacks1=[checkpoint1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "202/203 [============================>.] - ETA: 2s - loss: 3.3696Epoch 00000: saving model to /media/shreyas/DATA/ML_DATA/wheelai/gtaV/results/nvidia.h5\n",
      "203/203 [==============================] - 499s - loss: 3.3706 - val_loss: 1.1652\n",
      "Epoch 2/5\n",
      "202/203 [============================>.] - ETA: 0s - loss: 2.9307Epoch 00001: saving model to /media/shreyas/DATA/ML_DATA/wheelai/gtaV/results/nvidia.h5\n",
      "203/203 [==============================] - 167s - loss: 2.9268 - val_loss: 1.1566\n",
      "Epoch 3/5\n",
      "202/203 [============================>.] - ETA: 0s - loss: 2.5442Epoch 00002: saving model to /media/shreyas/DATA/ML_DATA/wheelai/gtaV/results/nvidia.h5\n",
      "203/203 [==============================] - 168s - loss: 2.5422 - val_loss: 1.1358\n",
      "Epoch 4/5\n",
      "202/203 [============================>.] - ETA: 0s - loss: 2.5563Epoch 00003: saving model to /media/shreyas/DATA/ML_DATA/wheelai/gtaV/results/nvidia.h5\n",
      "203/203 [==============================] - 167s - loss: 2.5560 - val_loss: 1.0897\n",
      "Epoch 5/5\n",
      "202/203 [============================>.] - ETA: 0s - loss: 2.3602Epoch 00004: saving model to /media/shreyas/DATA/ML_DATA/wheelai/gtaV/results/nvidia.h5\n",
      "203/203 [==============================] - 168s - loss: 2.3597 - val_loss: 1.0907\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f2204068898>"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit_generator(train_b, steps_per_epoch=train_steps, epochs=5, callbacks=callbacks1,\\\n",
    "                        validation_data=valid_b, validation_steps=valid_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "filepath2 = results_path+'nvidia_aug.h5'\n",
    "checkpoint2 = ModelCheckpoint(filepath2, monitor='val_loss', verbose=1, save_best_only=False,\\\n",
    "                             save_weights_only=True, mode='min', period=1)\n",
    "callbacks2=[checkpoint2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/8\n",
      "202/203 [============================>.] - ETA: 0s - loss: 2.2844Epoch 00000: saving model to /media/shreyas/DATA/ML_DATA/wheelai/gtaV/results/nvidia_aug.h5\n",
      "203/203 [==============================] - 234s - loss: 2.2824 - val_loss: 1.0971\n",
      "Epoch 2/8\n",
      "202/203 [============================>.] - ETA: 0s - loss: 2.2414Epoch 00001: saving model to /media/shreyas/DATA/ML_DATA/wheelai/gtaV/results/nvidia_aug.h5\n",
      "203/203 [==============================] - 223s - loss: 2.2388 - val_loss: 1.1082\n",
      "Epoch 3/8\n",
      "202/203 [============================>.] - ETA: 0s - loss: 2.2178Epoch 00002: saving model to /media/shreyas/DATA/ML_DATA/wheelai/gtaV/results/nvidia_aug.h5\n",
      "203/203 [==============================] - 224s - loss: 2.2156 - val_loss: 1.1135\n",
      "Epoch 4/8\n",
      "202/203 [============================>.] - ETA: 0s - loss: 2.0616Epoch 00003: saving model to /media/shreyas/DATA/ML_DATA/wheelai/gtaV/results/nvidia_aug.h5\n",
      "203/203 [==============================] - 223s - loss: 2.0604 - val_loss: 1.1320\n",
      "Epoch 5/8\n",
      "202/203 [============================>.] - ETA: 0s - loss: 1.9723Epoch 00004: saving model to /media/shreyas/DATA/ML_DATA/wheelai/gtaV/results/nvidia_aug.h5\n",
      "203/203 [==============================] - 225s - loss: 1.9741 - val_loss: 1.1575\n",
      "Epoch 6/8\n",
      "202/203 [============================>.] - ETA: 0s - loss: 1.9485Epoch 00005: saving model to /media/shreyas/DATA/ML_DATA/wheelai/gtaV/results/nvidia_aug.h5\n",
      "203/203 [==============================] - 224s - loss: 1.9506 - val_loss: 1.1193\n",
      "Epoch 7/8\n",
      "202/203 [============================>.] - ETA: 0s - loss: 1.9509Epoch 00006: saving model to /media/shreyas/DATA/ML_DATA/wheelai/gtaV/results/nvidia_aug.h5\n",
      "203/203 [==============================] - 223s - loss: 1.9495 - val_loss: 1.1244\n",
      "Epoch 8/8\n",
      "202/203 [============================>.] - ETA: 0s - loss: 1.9847Epoch 00007: saving model to /media/shreyas/DATA/ML_DATA/wheelai/gtaV/results/nvidia_aug.h5\n",
      "203/203 [==============================] - 223s - loss: 1.9840 - val_loss: 1.1220\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f220464fe10>"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit_generator(augtrain_b, steps_per_epoch=train_steps, epochs=8, callbacks=callbacks2,\\\n",
    "                        validation_data=valid_b, validation_steps=valid_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "202/203 [============================>.] - ETA: 0s - loss: 1.8814Epoch 00000: saving model to /media/shreyas/DATA/ML_DATA/wheelai/gtaV/results/nvidia_aug.h5\n",
      "203/203 [==============================] - 171s - loss: 1.8784 - val_loss: 1.1216\n",
      "Epoch 2/3\n",
      "202/203 [============================>.] - ETA: 0s - loss: 1.8432Epoch 00001: saving model to /media/shreyas/DATA/ML_DATA/wheelai/gtaV/results/nvidia_aug.h5\n",
      "203/203 [==============================] - 167s - loss: 1.8446 - val_loss: 1.1324\n",
      "Epoch 3/3\n",
      "202/203 [============================>.] - ETA: 0s - loss: 1.8280Epoch 00002: saving model to /media/shreyas/DATA/ML_DATA/wheelai/gtaV/results/nvidia_aug.h5\n",
      "203/203 [==============================] - 165s - loss: 1.8274 - val_loss: 1.1256\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f21fca46fd0>"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit_generator(train_b, steps_per_epoch=train_steps, epochs=3, callbacks=callbacks2,\\\n",
    "                        validation_data=valid_b, validation_steps=valid_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# serialize model to JSON\n",
    "model_path = results_path+'nvidia.json'\n",
    "model_path = results_path+'nvidia.json'\n",
    "model_json = model.to_json()\n",
    "with open(model_path, \"w\") as json_file:\n",
    "    json_file.write(model_json)\n",
    "# serialize weights to HDF5\n",
    "model.save_weights(filepath2)\n",
    "print(\"Saved model to disk\")"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
