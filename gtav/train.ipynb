{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "d = '/media/shreyas/DATA/ML_DATA/wheelai/gtav/train/'\n",
    "#d = '/media/shreyas/DATA/ML_DATA/wheelai/gtav/sample/'\n",
    "\n",
    "x_trn_path = d + 'x_trn.bc'\n",
    "y_trn_path = d + 'y_trn.bc'\n",
    "\n",
    "s_crp_path = d + 's_crp.bc'\n",
    "x_crp_path = '/home/shreyas/Downloads/data/x_crp.bc'\n",
    "v_crp_path = '/home/shreyas/Downloads/data/v_crp.bc'\n",
    "\n",
    "x_val_path = '/media/shreyas/DATA/ML_DATA/wheelai/gtav/valid/x_val.bc'\n",
    "y_val_path = '/media/shreyas/DATA/ML_DATA/wheelai/gtav/valid/y_val.bc'\n",
    "results_path = '/media/shreyas/DATA/ML_DATA/wheelai/gtav/results/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from __future__ import division, print_function\n",
    "\n",
    "import os, json\n",
    "from glob import glob\n",
    "import numpy as np\n",
    "from scipy import misc, ndimage\n",
    "from scipy.ndimage.interpolation import zoom\n",
    "\n",
    "import keras\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras import backend as K\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.models import Sequential, load_model,  Model\n",
    "from keras.layers.core import Flatten, Dense, Dropout, Lambda\n",
    "from keras.layers.convolutional import Conv2D, MaxPooling2D, ZeroPadding2D\n",
    "from keras.layers.pooling import GlobalAveragePooling2D\n",
    "from keras.optimizers import Adam, SGD\n",
    "from keras.preprocessing import image\n",
    "from keras.applications import VGG16\n",
    "from keras.layers import Input, Lambda, Cropping2D, Activation, ELU\n",
    "from keras.layers.merge import add, concatenate\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import bcolz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "x_trn = bcolz.open(x_trn_path)\n",
    "y_trn = bcolz.open(y_trn_path)\n",
    "x_val = bcolz.open(x_val_path)\n",
    "y_val = bcolz.open(y_val_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(x_trn.shape, y_trn.shape, x_val.shape, y_val.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate batches with [Keras ImageDataGenerator](https://keras.io/preprocessing/image/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "input_shape = (160, 320, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.utils import shuffle\n",
    "\n",
    "def get_train_batch(offset, batch_size):\n",
    "    end = offset + batch_size\n",
    "    return x_trn[offset:end], y_trn[offset:end]\n",
    "            \n",
    "def get_valid_batch(offset, batch_size):\n",
    "    end = offset + batch_size\n",
    "    return x_val[offset:end], y_val[offset:end]\n",
    "        \n",
    "def generate_batch(num_samples, batch_size=32, train=True):\n",
    "    \"\"\"generator return train data and valid data in batches\"\"\"\n",
    "    # Loop forever so the generator never terminates \n",
    "    while 1:\n",
    "        #x_trn, y_trn = shuffle(y_trn, y_trn)\n",
    "        for offset in range(0, num_samples, batch_size):\n",
    "            if train:\n",
    "                yield (get_train_batch(offset, batch_size))\n",
    "            else:\n",
    "                yield (get_valid_batch(offset, batch_size))\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### More about Data Augmentation with Keras [here](https://blog.keras.io/building-powerful-image-classification-models-using-very-little-data.html) and [here.](http://machinelearningmastery.com/image-augmentation-deep-learning-keras/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### More of Nvidia's [End to End Learning Model](https://devblogs.nvidia.com/parallelforall/deep-learning-self-driving-cars/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def nvidia_model():\n",
    "    '''Implements Nvidia's end to end learning model'''\n",
    "    # Croping the image to retain only road part of image\n",
    "    x = Input(shape=input_shape)\n",
    "    # layer to learn color space\n",
    "    color_s = Conv2D(3, (1,1), padding='same')(x)\n",
    "    # normalise to mean 0\n",
    "    norm = Lambda(lambda x: (x / 255.0) - 0.5)(color_s)\n",
    "    \n",
    "    conv_b1 = Conv2D(24, (3,3), padding='same', activation='relu')(norm)\n",
    "    batch_1 = BatchNormalization()(conv_b1)\n",
    "    max_pl1 = MaxPooling2D()(batch_1)\n",
    "    \n",
    "    conv_b2 = Conv2D(36, (3,3), padding='same', activation='relu')(max_pl1)\n",
    "    batch_2 = BatchNormalization()(conv_b2)\n",
    "    max_pl2 = MaxPooling2D()(batch_2)\n",
    "    \n",
    "    conv_b3 = Conv2D(48, (3,3), padding='same', activation='relu')(max_pl2)\n",
    "    batch_3 = BatchNormalization()(conv_b3)\n",
    "    max_pl3 = MaxPooling2D()(batch_3)\n",
    "    \n",
    "    conv_b4 = Conv2D(64, (3,3), padding='same', activation='relu')(max_pl3)\n",
    "    batch_4 = BatchNormalization()(conv_b4)\n",
    "    max_pl4 = MaxPooling2D()(batch_4)\n",
    "    dropout = Dropout(0.1)(max_pl4)\n",
    "    \n",
    "    conv_b5 = Conv2D(64, (3,3), padding='same', activation='relu')(dropout)\n",
    "    batch_5 = BatchNormalization()(conv_b5)\n",
    "    max_pl5 = MaxPooling2D((1,4))(batch_5)\n",
    "    dropout = Dropout(0.1)(max_pl5)\n",
    "    \n",
    "    flatten = Flatten()(dropout)\n",
    "    fc1 = Dense(100, activation='relu')(flatten)\n",
    "    batch_fc1 = BatchNormalization()(fc1)\n",
    "    drop_fc1 = Dropout(0.2)(batch_fc1)\n",
    "    \n",
    "    fc2 = Dense(50, activation='relu')(drop_fc1)\n",
    "    batch_fc2 = BatchNormalization()(fc2)\n",
    "    drop_fc2 = Dropout(0.3)(batch_fc2)\n",
    "    \n",
    "    fc3 = Dense(10, activation='relu')(drop_fc2)\n",
    "    batch_fc3 = BatchNormalization()(fc3)\n",
    "    drop_fc3 = Dropout(0.5)(batch_fc3)\n",
    "    \n",
    "    output = Dense(3)(drop_fc3)\n",
    "    \n",
    "    model = Model(inputs=x, outputs=output)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def nvidia_conv():\n",
    "    '''Implement a model similar to Nvidia end to end but with only conv layers'''\n",
    "    model = Sequential()\n",
    "    model.add(Lambda(lambda x: (x / 255.0) - 0.5, input_shape=input_shape))\n",
    "    model.add(Conv2D(3, (1,1), padding='same')) \n",
    "    model.add(Conv2D(24, (3,3), padding='same', activation='relu'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(MaxPooling2D())\n",
    "    model.add(Conv2D(36, (3,3), padding='same', activation='relu'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(MaxPooling2D())   \n",
    "    model.add(Conv2D(48, (3,3), padding='same', activation='relu'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(MaxPooling2D())\n",
    "    model.add(Conv2D(64, (3,3), padding='same', activation='relu'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(MaxPooling2D())\n",
    "    model.add(Conv2D(128, (3,3), padding='same', activation='relu'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(MaxPooling2D((1,4)))\n",
    "    model.add(Conv2D(3, (3,3), padding='same'))\n",
    "    model.add(GlobalAveragePooling2D())\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def commaai():\n",
    "    #ch, row, col = 3, 160, 320  # camera format\n",
    "\n",
    "    model = Sequential()\n",
    "    model.add(Lambda(lambda x: x/127.5 - 1.,input_shape=input_shape))\n",
    "    model.add(Conv2D(16, (8, 8), strides=(4, 4), padding=\"same\"))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(MaxPooling2D())\n",
    "    model.add(Conv2D(32, (5, 5), strides=(2, 2), padding=\"same\"))\n",
    "    model.add(Dropout(.1))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(MaxPooling2D())\n",
    "    model.add(Conv2D(64, (5, 5), strides=(2, 2), padding=\"same\"))\n",
    "    model.add(Dropout(.2))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(MaxPooling2D())\n",
    "    model.add(Flatten())\n",
    "    model.add(Dropout(.3))\n",
    "    model.add(Dense(512))\n",
    "    model.add(Dropout(.5))\n",
    "    model.add(ELU())\n",
    "    model.add(Dense(3))\n",
    "\n",
    "    model.compile(optimizer=\"adam\", loss=\"mse\")\n",
    "\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1 Nvidia Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model = nvidia_model()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "adam = Adam(lr=1e-4, beta_1=0.9, beta_2=0.999, epsilon=1e-08, decay=0.0)\n",
    "model.compile(optimizer=adam,loss='mse')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# serialize model to JSON\n",
    "model_path = results_path+'nvidia.json'\n",
    "model_json = model.to_json()\n",
    "with open(model_path, \"w\") as json_file:\n",
    "    json_file.write(model_json)\n",
    "\n",
    "print(\"Saved model to disk\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "trn_gen = generate_batch(x_trn.shape[0], batch_size)\n",
    "val_gen = generate_batch(x_val.shape[0], batch_size, train=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model.fit_generator(generator=trn_gen, steps_per_epoch=len(x_trn) / batch_size, epochs=10, verbose=1, \\\n",
    "                    validation_data=val_gen, validation_steps=len(x_val) / batch_size)\n",
    "\n",
    "model.save_weights(results_path+'nvidia1.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#filepath1 = results_path+'nvidia.h5'\n",
    "#checkpoint1 = ModelCheckpoint(filepath1, monitor='val_loss', verbose=1, save_best_only=False,\\\n",
    "#                             save_weights_only=True, mode='min', period=1)\n",
    "#callbacks1=[checkpoint1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model.optimizer.lr = 1e-5\n",
    "model.fit_generator(generator=trn_gen, steps_per_epoch=len(x_trn) / batch_size, epochs=10, verbose=1, \\\n",
    "                    validation_data=val_gen, validation_steps=len(x_val) / batch_size)\n",
    "\n",
    "model.save_weights(results_path+'nvidia2.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model.optimizer.lr = 1e-3\n",
    "model.fit_generator(generator=trn_gen, steps_per_epoch=len(x_trn) / batch_size, epochs=10, verbose=1, \\\n",
    "                    validation_data=val_gen, validation_steps=len(x_val) / batch_size)\n",
    "\n",
    "model.save_weights(results_path+'nvidia3.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#filepath2 = results_path+'nvidia_aug.h5'\n",
    "#checkpoint2 = ModelCheckpoint(filepath2, monitor='val_loss', verbose=1, save_best_only=False,\\\n",
    "#                             save_weights_only=True, mode='min', period=1)\n",
    "#callbacks2=[checkpoint2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model.optimizer.lr = 1e-5\n",
    "model.fit_generator(generator=trn_gen, steps_per_epoch=len(x_trn) / batch_size, epochs=10, verbose=1, \\\n",
    "                    validation_data=val_gen, validation_steps=len(x_val) / batch_size)\n",
    "\n",
    "model.save_weights(results_path+'nvidia4.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model.optimizer.lr = 1e-4\n",
    "model.fit_generator(generator=trn_gen, steps_per_epoch=len(x_trn) / batch_size, epochs=10, verbose=1, \\\n",
    "                    validation_data=val_gen, validation_steps=len(x_val) / batch_size)\n",
    "\n",
    "model.save_weights(results_path+'nvidia5.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model.optimizer.lr = 1e-5\n",
    "model.fit_generator(generator=trn_gen, steps_per_epoch=len(x_trn) / batch_size, epochs=10, verbose=1, \\\n",
    "                    validation_data=val_gen, validation_steps=len(x_val) / batch_size)\n",
    "\n",
    "model.save_weights(results_path+'nvidia6.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2 Nvidia All CONV model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model = nvidia_conv()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model.compile(optimizer=\"adam\", loss=\"mse\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# serialize model to JSON\n",
    "model_path = results_path+'nvidia_conv.json'\n",
    "model_json = model.to_json()\n",
    "with open(model_path, \"w\") as json_file:\n",
    "    json_file.write(model_json)\n",
    "\n",
    "print(\"Saved model to disk\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "trn_gen = generate_batch(x_trn.shape[0], batch_size)\n",
    "val_gen = generate_batch(x_val.shape[0], batch_size, train=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model.fit_generator(generator=trn_gen, steps_per_epoch=len(x_trn) / batch_size, epochs=10, verbose=1, \\\n",
    "                    validation_data=val_gen, validation_steps=len(x_val) / batch_size)\n",
    "\n",
    "model.save_weights(results_path+'nvidia_conv1.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model.optimizer.lr = 1e-5\n",
    "model.fit_generator(generator=trn_gen, steps_per_epoch=len(x_trn) / batch_size, epochs=10, verbose=1, \\\n",
    "                    validation_data=val_gen, validation_steps=len(x_val) / batch_size)\n",
    "\n",
    "model.save_weights(results_path+'nvidia_conv2.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model.optimizer.lr = 1e-3\n",
    "model.fit_generator(generator=trn_gen, steps_per_epoch=len(x_trn) / batch_size, epochs=10, verbose=1, \\\n",
    "                    validation_data=val_gen, validation_steps=len(x_val) / batch_size)\n",
    "\n",
    "model.save_weights(results_path+'nvidia_conv3.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#filepath2 = results_path+'nvidia_aug.h5'\n",
    "#checkpoint2 = ModelCheckpoint(filepath2, monitor='val_loss', verbose=1, save_best_only=False,\\\n",
    "#                             save_weights_only=True, mode='min', period=1)\n",
    "#callbacks2=[checkpoint2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model.optimizer.lr = 1e-5\n",
    "model.fit_generator(generator=trn_gen, steps_per_epoch=len(x_trn) / batch_size, epochs=10, verbose=1, \\\n",
    "                    validation_data=val_gen, validation_steps=len(x_val) / batch_size)\n",
    "\n",
    "model.save_weights(results_path+'nvidia_conv4.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model.optimizer.lr = 1e-4\n",
    "model.fit_generator(generator=trn_gen, steps_per_epoch=len(x_trn) / batch_size, epochs=10, verbose=1, \\\n",
    "                    validation_data=val_gen, validation_steps=len(x_val) / batch_size)\n",
    "\n",
    "model.save_weights(results_path+'nvidia_conv5.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model.optimizer.lr = 1e-5\n",
    "model.fit_generator(generator=trn_gen, steps_per_epoch=len(x_trn) / batch_size, epochs=10, verbose=1, \\\n",
    "                    validation_data=val_gen, validation_steps=len(x_val) / batch_size)\n",
    "\n",
    "model.save_weights(results_path+'nvidia_conv6.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3 CommaAI Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model = commaai()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# serialize model to JSON\n",
    "model_path = results_path+'commaai.json'\n",
    "model_json = model.to_json()\n",
    "with open(model_path, \"w\") as json_file:\n",
    "    json_file.write(model_json)\n",
    "\n",
    "print(\"Saved model to disk\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "trn_gen = generate_batch(x_trn.shape[0], batch_size)\n",
    "val_gen = generate_batch(x_val.shape[0], batch_size, train=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model.load_weights(results_path+'commaai6.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "\n",
    "model.fit_generator(generator=trn_gen, steps_per_epoch=len(x_trn) / batch_size, epochs=10, verbose=1, \\\n",
    "                    validation_data=val_gen, validation_steps=len(x_val) / batch_size)\n",
    "\n",
    "model.save_weights(results_path+'commaai1.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model.optimizer.lr = 1e-5\n",
    "model.fit_generator(generator=trn_gen, steps_per_epoch=len(x_trn) / batch_size, epochs=10, verbose=1, \\\n",
    "                    validation_data=val_gen, validation_steps=len(x_val) / batch_size)\n",
    "\n",
    "model.save_weights(results_path+'commaai2.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model.optimizer.lr = 1e-3\n",
    "model.fit_generator(generator=trn_gen, steps_per_epoch=len(x_trn) / batch_size, epochs=10, verbose=1, \\\n",
    "                    validation_data=val_gen, validation_steps=len(x_val) / batch_size)\n",
    "\n",
    "model.save_weights(results_path+'commaai3.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#filepath2 = results_path+'nvidia_aug.h5'\n",
    "#checkpoint2 = ModelCheckpoint(filepath2, monitor='val_loss', verbose=1, save_best_only=False,\\\n",
    "#                             save_weights_only=True, mode='min', period=1)\n",
    "#callbacks2=[checkpoint2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model.optimizer.lr = 1e-4\n",
    "model.fit_generator(generator=trn_gen, steps_per_epoch=len(x_trn) / batch_size, epochs=10, verbose=1, \\\n",
    "                    validation_data=val_gen, validation_steps=len(x_val) / batch_size)\n",
    "\n",
    "model.save_weights(results_path+'commaai4.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model.optimizer.lr = 1e-3\n",
    "model.fit_generator(generator=trn_gen, steps_per_epoch=len(x_trn) / batch_size, epochs=10, verbose=1, \\\n",
    "                    validation_data=val_gen, validation_steps=len(x_val) / batch_size)\n",
    "\n",
    "model.save_weights(results_path+'commaai5.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model.optimizer.lr = 1e-5\n",
    "model.fit_generator(generator=trn_gen, steps_per_epoch=len(x_trn) / batch_size, epochs=10, verbose=1, \\\n",
    "                    validation_data=val_gen, validation_steps=len(x_val) / batch_size)\n",
    "\n",
    "model.save_weights(results_path+'commaai6.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model.optimizer.lr = 1e-5\n",
    "model.fit_generator(generator=trn_gen, steps_per_epoch=len(x_trn) / batch_size, epochs=10, verbose=1, \\\n",
    "                    validation_data=val_gen, validation_steps=len(x_val) / batch_size)\n",
    "\n",
    "model.save_weights(results_path+'commaai7.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model.optimizer.lr = 1e-5\n",
    "model.fit_generator(generator=trn_gen, steps_per_epoch=len(x_trn) / batch_size, epochs=10, verbose=1, \\\n",
    "                    validation_data=val_gen, validation_steps=len(x_val) / batch_size)\n",
    "\n",
    "model.save_weights(results_path+'commaai8.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
