{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "d = '/media/shreyas/DATA/ML_DATA/wheelai/gtav/train/'\n",
    "#d = '/media/shreyas/DATA/ML_DATA/wheelai/gtav/sample/'\n",
    "\n",
    "x_trn_path = '/home/shreyas/Downloads/data/x_trn.bc'\n",
    "y_trn_path = d + 'y_trn.bc'\n",
    "\n",
    "s_crp_path = d + 's_crp.bc'\n",
    "x_crp_path = '/home/shreyas/Downloads/data/x_crp.bc'\n",
    "v_crp_path = '/home/shreyas/Downloads/data/v_crp.bc'\n",
    "\n",
    "x_val_path = '/media/shreyas/DATA/ML_DATA/wheelai/gtav/valid/x_val.bc'\n",
    "y_val_path = '/media/shreyas/DATA/ML_DATA/wheelai/gtav/valid/y_val.bc'\n",
    "results_path = '/media/shreyas/DATA/ML_DATA/wheelai/gtav/results/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from __future__ import division, print_function\n",
    "\n",
    "import os, json\n",
    "from glob import glob\n",
    "import numpy as np\n",
    "from scipy import misc, ndimage\n",
    "from scipy.ndimage.interpolation import zoom\n",
    "\n",
    "import keras\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras import backend as K\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.models import Sequential, load_model,  Model\n",
    "from keras.layers.core import Flatten, Dense, Dropout, Lambda\n",
    "from keras.layers.convolutional import Conv2D, MaxPooling2D, ZeroPadding2D\n",
    "from keras.layers.pooling import GlobalAveragePooling2D\n",
    "from keras.optimizers import Adam, SGD\n",
    "from keras.preprocessing import image\n",
    "from keras.applications import VGG16\n",
    "from keras.layers import Input, Lambda, Cropping2D, Activation, ELU\n",
    "from keras.layers.merge import add, concatenate\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import bcolz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "x_trn = bcolz.open(x_trn_path)\n",
    "y_trn = bcolz.open(y_trn_path)\n",
    "x_val = bcolz.open(x_val_path)\n",
    "y_val = bcolz.open(y_val_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(545676, 160, 320, 3) (545676, 3) (18885, 160, 320, 3) (18885, 3)\n"
     ]
    }
   ],
   "source": [
    "print(x_trn.shape, y_trn.shape, x_val.shape, y_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "input_shape = (160, 320, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.utils import shuffle\n",
    "\n",
    "def get_train_batch(offset, batch_size):\n",
    "    end = offset + batch_size\n",
    "    return x_trn[offset:end], y_trn[offset:end]\n",
    "            \n",
    "def get_valid_batch(offset, batch_size):\n",
    "    end = offset + batch_size\n",
    "    return x_val[offset:end], y_val[offset:end]\n",
    "        \n",
    "def generate_batch(num_samples, batch_size=32, train=True):\n",
    "    \"\"\"generator return train data and valid data in batches\"\"\"\n",
    "    # Loop forever so the generator never terminates \n",
    "    while 1:\n",
    "        #x_trn, y_trn = shuffle(y_trn, y_trn)\n",
    "        for offset in range(0, num_samples, batch_size):\n",
    "            if train:\n",
    "                yield (get_train_batch(offset, batch_size))\n",
    "            else:\n",
    "                yield (get_valid_batch(offset, batch_size))\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### More of Nvidia's [End to End Learning Model](https://devblogs.nvidia.com/parallelforall/deep-learning-self-driving-cars/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def nvidia_model():\n",
    "    '''Implements Nvidia's end to end learning model'''\n",
    "    # Croping the image to retain only road part of image\n",
    "    x = Input(shape=input_shape)\n",
    "    # layer to learn color space\n",
    "    color_s = Conv2D(3, (1,1), padding='same')(x)\n",
    "    # normalise to mean 0\n",
    "    norm = Lambda(lambda x: (x / 255.0) - 0.5)(color_s)\n",
    "    \n",
    "    conv_b1 = Conv2D(24, (3,3), padding='same', activation='relu')(norm)\n",
    "    batch_1 = BatchNormalization()(conv_b1)\n",
    "    max_pl1 = MaxPooling2D()(batch_1)\n",
    "    \n",
    "    conv_b2 = Conv2D(36, (3,3), padding='same', activation='relu')(max_pl1)\n",
    "    batch_2 = BatchNormalization()(conv_b2)\n",
    "    max_pl2 = MaxPooling2D()(batch_2)\n",
    "    \n",
    "    conv_b3 = Conv2D(48, (3,3), padding='same', activation='relu')(max_pl2)\n",
    "    batch_3 = BatchNormalization()(conv_b3)\n",
    "    max_pl3 = MaxPooling2D()(batch_3)\n",
    "    \n",
    "    conv_b4 = Conv2D(64, (3,3), padding='same', activation='relu')(max_pl3)\n",
    "    batch_4 = BatchNormalization()(conv_b4)\n",
    "    max_pl4 = MaxPooling2D()(batch_4)\n",
    "    dropout = Dropout(0.1)(max_pl4)\n",
    "    \n",
    "    conv_b5 = Conv2D(64, (3,3), padding='same', activation='relu')(dropout)\n",
    "    batch_5 = BatchNormalization()(conv_b5)\n",
    "    max_pl5 = MaxPooling2D((1,4))(batch_5)\n",
    "    dropout = Dropout(0.1)(max_pl5)\n",
    "    \n",
    "    flatten = Flatten()(dropout)\n",
    "    fc1 = Dense(100, activation='relu')(flatten)\n",
    "    batch_fc1 = BatchNormalization()(fc1)\n",
    "    drop_fc1 = Dropout(0.2)(batch_fc1)\n",
    "    \n",
    "    fc2 = Dense(50, activation='relu')(drop_fc1)\n",
    "    batch_fc2 = BatchNormalization()(fc2)\n",
    "    drop_fc2 = Dropout(0.3)(batch_fc2)\n",
    "    \n",
    "    fc3 = Dense(10, activation='relu')(drop_fc2)\n",
    "    batch_fc3 = BatchNormalization()(fc3)\n",
    "    drop_fc3 = Dropout(0.5)(batch_fc3)\n",
    "    \n",
    "    output = Dense(3)(drop_fc3)\n",
    "    \n",
    "    model = Model(inputs=x, outputs=output)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def nvidia_conv():\n",
    "    '''Implement a model similar to Nvidia end to end but with only conv layers'''\n",
    "    model = Sequential()\n",
    "    model.add(Lambda(lambda x: (x / 255.0) - 0.5, input_shape=input_shape))\n",
    "    model.add(Conv2D(3, (1,1), padding='same')) \n",
    "    model.add(Conv2D(24, (3,3), padding='same', activation='elu'))\n",
    "    #model.add(BatchNormalization())\n",
    "    model.add(MaxPooling2D())\n",
    "    model.add(Conv2D(36, (3,3), padding='same', activation='elu'))\n",
    "    #model.add(BatchNormalization())\n",
    "    model.add(MaxPooling2D())   \n",
    "    model.add(Conv2D(48, (3,3), padding='same', activation='elu'))\n",
    "    #model.add(BatchNormalization())\n",
    "    model.add(MaxPooling2D())\n",
    "    model.add(Conv2D(64, (3,3), padding='same', activation='elu'))\n",
    "    #model.add(BatchNormalization())\n",
    "    model.add(MaxPooling2D())\n",
    "    model.add(Conv2D(128, (3,3), padding='same', activation='elu'))\n",
    "    #model.add(BatchNormalization())\n",
    "    model.add(MaxPooling2D((1,4)))\n",
    "    model.add(Conv2D(3, (3,3), padding='same'))\n",
    "    model.add(GlobalAveragePooling2D())\n",
    "    model.add(Dense(3))\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def commaai():\n",
    "    #ch, row, col = 3, 160, 320  # camera format\n",
    "\n",
    "    model = Sequential()\n",
    "    model.add(Lambda(lambda x: x/127.5 - 1.,input_shape=input_shape))\n",
    "    model.add(Conv2D(16, (8, 8), strides=(4, 4), padding=\"same\"))\n",
    "    #model.add(BatchNormalization())\n",
    "    model.add(Activation('elu'))\n",
    "    model.add(MaxPooling2D())\n",
    "    model.add(Conv2D(32, (5, 5), strides=(2, 2), padding=\"same\"))\n",
    "    model.add(Dropout(.1))\n",
    "    #model.add(BatchNormalization())\n",
    "    model.add(Activation('elu'))\n",
    "    model.add(MaxPooling2D((1,2)))\n",
    "    model.add(Conv2D(64, (5, 5), strides=(2, 2), padding=\"same\"))\n",
    "    model.add(Dropout(.2))\n",
    "    #model.add(BatchNormalization())\n",
    "    model.add(Activation('elu'))\n",
    "    model.add(MaxPooling2D())\n",
    "    model.add(Flatten())\n",
    "    model.add(Dropout(.3))\n",
    "    model.add(Dense(512))\n",
    "    model.add(Dropout(.5))\n",
    "    model.add(ELU())\n",
    "    model.add(Dense(3))\n",
    "\n",
    "    model.compile(optimizer=\"adam\", loss=\"mse\")\n",
    "\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1 CommaAI Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lambda_2 (Lambda)            (None, 160, 320, 3)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 40, 80, 16)        3088      \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 40, 80, 16)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2 (None, 20, 40, 16)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 10, 20, 32)        12832     \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 10, 20, 32)        0         \n",
      "_________________________________________________________________\n",
      "activation_5 (Activation)    (None, 10, 20, 32)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_5 (MaxPooling2 (None, 10, 10, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_6 (Conv2D)            (None, 5, 5, 64)          51264     \n",
      "_________________________________________________________________\n",
      "dropout_6 (Dropout)          (None, 5, 5, 64)          0         \n",
      "_________________________________________________________________\n",
      "activation_6 (Activation)    (None, 5, 5, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_6 (MaxPooling2 (None, 2, 2, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dropout_7 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 512)               131584    \n",
      "_________________________________________________________________\n",
      "dropout_8 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "elu_2 (ELU)                  (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 3)                 1539      \n",
      "=================================================================\n",
      "Total params: 200,307\n",
      "Trainable params: 200,307\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = commaai()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved model to disk\n"
     ]
    }
   ],
   "source": [
    "# serialize model to JSON\n",
    "model_path = results_path+'commaai.json'\n",
    "model_json = model.to_json()\n",
    "with open(model_path, \"w\") as json_file:\n",
    "    json_file.write(model_json)\n",
    "\n",
    "print(\"Saved model to disk\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "trn_gen = generate_batch(x_trn.shape[0], batch_size)\n",
    "val_gen = generate_batch(x_val.shape[0], batch_size, train=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "4264/4263 [==============================] - 400s - loss: 0.0611 - val_loss: 0.3931\n",
      "Epoch 2/10\n",
      "4264/4263 [==============================] - 459s - loss: 0.0771 - val_loss: 1.0703\n",
      "Epoch 3/10\n",
      "4264/4263 [==============================] - 387s - loss: 0.0673 - val_loss: 1.0616\n",
      "Epoch 4/10\n",
      "4264/4263 [==============================] - 356s - loss: 0.0793 - val_loss: 0.9807\n",
      "Epoch 5/10\n",
      "4264/4263 [==============================] - 352s - loss: 0.0684 - val_loss: 1.0060\n",
      "Epoch 6/10\n",
      "4264/4263 [==============================] - 422s - loss: 0.0694 - val_loss: 1.0194\n",
      "Epoch 7/10\n",
      "4264/4263 [==============================] - 430s - loss: 0.0683 - val_loss: 1.0063\n",
      "Epoch 8/10\n",
      "4264/4263 [==============================] - 359s - loss: 0.0678 - val_loss: 1.0044\n",
      "Epoch 9/10\n",
      "4264/4263 [==============================] - 306s - loss: 0.0674 - val_loss: 0.9490\n",
      "Epoch 10/10\n",
      "4264/4263 [==============================] - 292s - loss: 0.0678 - val_loss: 0.9587\n"
     ]
    }
   ],
   "source": [
    "model.fit_generator(generator=trn_gen, steps_per_epoch=len(x_trn) / batch_size, epochs=10, verbose=1, \\\n",
    "                    validation_data=val_gen, validation_steps=len(x_val) / batch_size)\n",
    "\n",
    "model.save_weights(results_path+'commaai1.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "4264/4263 [==============================] - 305s - loss: 0.0674 - val_loss: 0.8246\n",
      "Epoch 2/10\n",
      "4264/4263 [==============================] - 326s - loss: 0.0672 - val_loss: 0.4265\n",
      "Epoch 3/10\n",
      "4264/4263 [==============================] - 327s - loss: 0.0672 - val_loss: 0.6218\n",
      "Epoch 4/10\n",
      "4264/4263 [==============================] - 373s - loss: 0.0673 - val_loss: 0.1989\n",
      "Epoch 5/10\n",
      "4264/4263 [==============================] - 410s - loss: 0.0673 - val_loss: 0.2903\n",
      "Epoch 6/10\n",
      "4264/4263 [==============================] - 434s - loss: 0.0674 - val_loss: 0.3024\n",
      "Epoch 7/10\n",
      "4264/4263 [==============================] - 438s - loss: 0.0674 - val_loss: 0.1716\n",
      "Epoch 8/10\n",
      "4264/4263 [==============================] - 438s - loss: 0.0674 - val_loss: 0.1121\n",
      "Epoch 9/10\n",
      "4264/4263 [==============================] - 435s - loss: 0.0676 - val_loss: 0.0608\n",
      "Epoch 10/10\n",
      "4264/4263 [==============================] - 417s - loss: 0.0677 - val_loss: 0.0506\n"
     ]
    }
   ],
   "source": [
    "model.optimizer.lr = 1e-5\n",
    "model.fit_generator(generator=trn_gen, steps_per_epoch=len(x_trn) / batch_size, epochs=10, verbose=1, \\\n",
    "                    validation_data=val_gen, validation_steps=len(x_val) / batch_size)\n",
    "\n",
    "model.save_weights(results_path+'commaai2.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "4264/4263 [==============================] - 303s - loss: 0.0677 - val_loss: 0.5960\n",
      "Epoch 2/10\n",
      "4264/4263 [==============================] - 320s - loss: 0.0677 - val_loss: 0.6959\n",
      "Epoch 3/10\n",
      "4264/4263 [==============================] - 316s - loss: 0.0677 - val_loss: 0.4711\n",
      "Epoch 4/10\n",
      "4264/4263 [==============================] - 299s - loss: 0.0677 - val_loss: 0.4745\n",
      "Epoch 5/10\n",
      "4264/4263 [==============================] - 296s - loss: 0.0679 - val_loss: 0.5044\n",
      "Epoch 6/10\n",
      "4264/4263 [==============================] - 293s - loss: 0.0679 - val_loss: 0.5069\n",
      "Epoch 7/10\n",
      "4264/4263 [==============================] - 301s - loss: 0.0679 - val_loss: 0.4707\n",
      "Epoch 8/10\n",
      "4264/4263 [==============================] - 296s - loss: 0.0679 - val_loss: 0.5075\n",
      "Epoch 9/10\n",
      "4264/4263 [==============================] - 342s - loss: 0.0679 - val_loss: 0.3629\n",
      "Epoch 10/10\n",
      "4264/4263 [==============================] - 348s - loss: 0.0680 - val_loss: 0.3827\n"
     ]
    }
   ],
   "source": [
    "model.optimizer.lr = 1e-3\n",
    "model.fit_generator(generator=trn_gen, steps_per_epoch=len(x_trn) / batch_size, epochs=10, verbose=1, \\\n",
    "                    validation_data=val_gen, validation_steps=len(x_val) / batch_size)\n",
    "\n",
    "model.save_weights(results_path+'commaai3.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#filepath2 = results_path+'nvidia_aug.h5'\n",
    "#checkpoint2 = ModelCheckpoint(filepath2, monitor='val_loss', verbose=1, save_best_only=False,\\\n",
    "#                             save_weights_only=True, mode='min', period=1)\n",
    "#callbacks2=[checkpoint2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "4264/4263 [==============================] - 365s - loss: 0.0681 - val_loss: 0.3069\n",
      "Epoch 2/10\n",
      "4264/4263 [==============================] - 388s - loss: 0.0681 - val_loss: 0.2275\n",
      "Epoch 3/10\n",
      "4264/4263 [==============================] - 394s - loss: 0.0681 - val_loss: 0.3215\n",
      "Epoch 4/10\n",
      "4264/4263 [==============================] - 409s - loss: 0.0681 - val_loss: 0.3500\n",
      "Epoch 5/10\n",
      "4264/4263 [==============================] - 430s - loss: 0.0681 - val_loss: 0.2233\n",
      "Epoch 6/10\n",
      "4264/4263 [==============================] - 372s - loss: 0.0682 - val_loss: 0.2588\n",
      "Epoch 7/10\n",
      "4264/4263 [==============================] - 344s - loss: 0.0682 - val_loss: 0.2528\n",
      "Epoch 8/10\n",
      "4264/4263 [==============================] - 369s - loss: 0.0683 - val_loss: 0.2318\n",
      "Epoch 9/10\n",
      "4264/4263 [==============================] - 383s - loss: 0.0683 - val_loss: 0.4475\n",
      "Epoch 10/10\n",
      "4264/4263 [==============================] - 337s - loss: 0.0684 - val_loss: 0.2895\n"
     ]
    }
   ],
   "source": [
    "model.optimizer.lr = 1e-5\n",
    "model.fit_generator(generator=trn_gen, steps_per_epoch=len(x_trn) / batch_size, epochs=10, verbose=1, \\\n",
    "                    validation_data=val_gen, validation_steps=len(x_val) / batch_size)\n",
    "\n",
    "model.save_weights(results_path+'commaai4.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "4264/4263 [==============================] - 349s - loss: 0.0683 - val_loss: 0.2431\n",
      "Epoch 2/10\n",
      "4264/4263 [==============================] - 351s - loss: 0.0684 - val_loss: 0.2737\n",
      "Epoch 3/10\n",
      "4264/4263 [==============================] - 379s - loss: 0.0684 - val_loss: 0.2421\n",
      "Epoch 4/10\n",
      "4264/4263 [==============================] - 414s - loss: 0.0685 - val_loss: 0.2384\n",
      "Epoch 5/10\n",
      "4264/4263 [==============================] - 413s - loss: 0.0684 - val_loss: 0.2651\n",
      "Epoch 6/10\n",
      "4264/4263 [==============================] - 418s - loss: 0.0685 - val_loss: 0.2508\n",
      "Epoch 7/10\n",
      "4264/4263 [==============================] - 432s - loss: 0.0686 - val_loss: 0.2447\n",
      "Epoch 8/10\n",
      "4264/4263 [==============================] - 433s - loss: 0.0685 - val_loss: 0.2757\n",
      "Epoch 9/10\n",
      "4264/4263 [==============================] - 437s - loss: 0.0686 - val_loss: 0.2306\n",
      "Epoch 10/10\n",
      "4264/4263 [==============================] - 439s - loss: 0.0685 - val_loss: 0.2830\n"
     ]
    }
   ],
   "source": [
    "model.optimizer.lr = 1e-4\n",
    "model.fit_generator(generator=trn_gen, steps_per_epoch=len(x_trn) / batch_size, epochs=10, verbose=1, \\\n",
    "                    validation_data=val_gen, validation_steps=len(x_val) / batch_size)\n",
    "\n",
    "model.save_weights(results_path+'commaai5.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "4264/4263 [==============================] - 336s - loss: 0.0686 - val_loss: 0.2827\n",
      "Epoch 2/10\n",
      "4264/4263 [==============================] - 325s - loss: 0.0685 - val_loss: 0.2383\n",
      "Epoch 3/10\n",
      "4264/4263 [==============================] - 334s - loss: 0.0687 - val_loss: 0.2990\n",
      "Epoch 4/10\n",
      "4264/4263 [==============================] - 347s - loss: 0.0685 - val_loss: 0.2543\n",
      "Epoch 5/10\n",
      "4264/4263 [==============================] - 354s - loss: 0.0686 - val_loss: 0.2636\n",
      "Epoch 6/10\n",
      "4264/4263 [==============================] - 366s - loss: 0.0686 - val_loss: 0.2645\n",
      "Epoch 7/10\n",
      "4264/4263 [==============================] - 365s - loss: 0.0687 - val_loss: 0.2732\n",
      "Epoch 8/10\n",
      "4264/4263 [==============================] - 363s - loss: 0.0688 - val_loss: 0.2673\n",
      "Epoch 9/10\n",
      "4264/4263 [==============================] - 370s - loss: 0.0687 - val_loss: 0.2859\n",
      "Epoch 10/10\n",
      "4264/4263 [==============================] - 371s - loss: 0.0687 - val_loss: 0.2646\n"
     ]
    }
   ],
   "source": [
    "model.optimizer.lr = 1e-5\n",
    "model.fit_generator(generator=trn_gen, steps_per_epoch=len(x_trn) / batch_size, epochs=10, verbose=1, \\\n",
    "                    validation_data=val_gen, validation_steps=len(x_val) / batch_size)\n",
    "\n",
    "model.save_weights(results_path+'commaai6.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "4264/4263 [==============================] - 393s - loss: 0.0692 - val_loss: 1.0369\n",
      "Epoch 2/10\n",
      "4264/4263 [==============================] - 423s - loss: 0.0687 - val_loss: 1.0897\n",
      "Epoch 3/10\n",
      "4264/4263 [==============================] - 434s - loss: 0.0688 - val_loss: 1.1074\n",
      "Epoch 4/10\n",
      "4264/4263 [==============================] - 438s - loss: 0.0687 - val_loss: 1.0036\n",
      "Epoch 5/10\n",
      "4264/4263 [==============================] - 441s - loss: 0.0687 - val_loss: 0.9539\n",
      "Epoch 6/10\n",
      "4264/4263 [==============================] - 421s - loss: 0.0688 - val_loss: 1.0153\n",
      "Epoch 7/10\n",
      "4264/4263 [==============================] - 322s - loss: 0.0689 - val_loss: 0.9910\n",
      "Epoch 8/10\n",
      "4264/4263 [==============================] - 326s - loss: 0.0688 - val_loss: 1.1065\n",
      "Epoch 9/10\n",
      "4264/4263 [==============================] - 315s - loss: 0.0689 - val_loss: 1.1128\n",
      "Epoch 10/10\n",
      "4264/4263 [==============================] - 315s - loss: 0.0688 - val_loss: 0.9888\n"
     ]
    }
   ],
   "source": [
    "model.optimizer.lr = 1e-4\n",
    "model.fit_generator(generator=trn_gen, steps_per_epoch=len(x_trn) / batch_size, epochs=10, verbose=1, \\\n",
    "                    validation_data=val_gen, validation_steps=len(x_val) / batch_size)\n",
    "\n",
    "model.save_weights(results_path+'commaai7.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "4264/4263 [==============================] - 322s - loss: 0.0690 - val_loss: 0.9896\n",
      "Epoch 2/10\n",
      "4264/4263 [==============================] - 340s - loss: 0.0689 - val_loss: 0.9875\n",
      "Epoch 3/10\n",
      "4264/4263 [==============================] - 357s - loss: 0.0689 - val_loss: 1.0992\n",
      "Epoch 4/10\n",
      "4264/4263 [==============================] - 363s - loss: 0.0690 - val_loss: 1.2068\n",
      "Epoch 5/10\n",
      "4264/4263 [==============================] - 344s - loss: 0.0689 - val_loss: 1.0525\n",
      "Epoch 6/10\n",
      "4264/4263 [==============================] - 360s - loss: 0.0690 - val_loss: 1.0442\n",
      "Epoch 7/10\n",
      "4264/4263 [==============================] - 373s - loss: 0.0690 - val_loss: 1.1774\n",
      "Epoch 8/10\n",
      "4264/4263 [==============================] - 384s - loss: 0.0690 - val_loss: 1.1604\n",
      "Epoch 9/10\n",
      "4264/4263 [==============================] - 431s - loss: 0.0689 - val_loss: 1.1016\n",
      "Epoch 10/10\n",
      "4264/4263 [==============================] - 454s - loss: 0.0690 - val_loss: 1.0779\n"
     ]
    }
   ],
   "source": [
    "model.optimizer.lr = 1e-5\n",
    "model.fit_generator(generator=trn_gen, steps_per_epoch=len(x_trn) / batch_size, epochs=10, verbose=1, \\\n",
    "                    validation_data=val_gen, validation_steps=len(x_val) / batch_size)\n",
    "\n",
    "model.save_weights(results_path+'commaai8.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2 Nvidia Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 160, 320, 3)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_7 (Conv2D)            (None, 160, 320, 3)       12        \n",
      "_________________________________________________________________\n",
      "lambda_3 (Lambda)            (None, 160, 320, 3)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_8 (Conv2D)            (None, 160, 320, 24)      672       \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 160, 320, 24)      96        \n",
      "_________________________________________________________________\n",
      "max_pooling2d_7 (MaxPooling2 (None, 80, 160, 24)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_9 (Conv2D)            (None, 80, 160, 36)       7812      \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 80, 160, 36)       144       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_8 (MaxPooling2 (None, 40, 80, 36)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_10 (Conv2D)           (None, 40, 80, 48)        15600     \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 40, 80, 48)        192       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_9 (MaxPooling2 (None, 20, 40, 48)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_11 (Conv2D)           (None, 20, 40, 64)        27712     \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch (None, 20, 40, 64)        256       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_10 (MaxPooling (None, 10, 20, 64)        0         \n",
      "_________________________________________________________________\n",
      "dropout_9 (Dropout)          (None, 10, 20, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_12 (Conv2D)           (None, 10, 20, 64)        36928     \n",
      "_________________________________________________________________\n",
      "batch_normalization_5 (Batch (None, 10, 20, 64)        256       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_11 (MaxPooling (None, 10, 5, 64)         0         \n",
      "_________________________________________________________________\n",
      "dropout_10 (Dropout)         (None, 10, 5, 64)         0         \n",
      "_________________________________________________________________\n",
      "flatten_3 (Flatten)          (None, 3200)              0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 100)               320100    \n",
      "_________________________________________________________________\n",
      "batch_normalization_6 (Batch (None, 100)               400       \n",
      "_________________________________________________________________\n",
      "dropout_11 (Dropout)         (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 50)                5050      \n",
      "_________________________________________________________________\n",
      "batch_normalization_7 (Batch (None, 50)                200       \n",
      "_________________________________________________________________\n",
      "dropout_12 (Dropout)         (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 10)                510       \n",
      "_________________________________________________________________\n",
      "batch_normalization_8 (Batch (None, 10)                40        \n",
      "_________________________________________________________________\n",
      "dropout_13 (Dropout)         (None, 10)                0         \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 3)                 33        \n",
      "=================================================================\n",
      "Total params: 416,013\n",
      "Trainable params: 415,221\n",
      "Non-trainable params: 792\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = nvidia_model()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "adam = Adam(lr=1e-4, beta_1=0.9, beta_2=0.999, epsilon=1e-08, decay=0.0)\n",
    "model.compile(optimizer=adam,loss='mse')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved model to disk\n"
     ]
    }
   ],
   "source": [
    "# serialize model to JSON\n",
    "model_path = results_path+'nvidia.json'\n",
    "model_json = model.to_json()\n",
    "with open(model_path, \"w\") as json_file:\n",
    "    json_file.write(model_json)\n",
    "\n",
    "print(\"Saved model to disk\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "trn_gen = generate_batch(x_trn.shape[0], batch_size)\n",
    "val_gen = generate_batch(x_val.shape[0], batch_size, train=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "4264/4263 [==============================] - 4327s - loss: 1.0730 - val_loss: 2.1095\n",
      "Epoch 2/10\n",
      "4264/4263 [==============================] - 4312s - loss: 0.1688 - val_loss: 0.3281\n",
      "Epoch 3/10\n",
      "4264/4263 [==============================] - 4319s - loss: 0.0916 - val_loss: 0.1445\n",
      "Epoch 4/10\n",
      "4264/4263 [==============================] - 4318s - loss: 0.0860 - val_loss: 0.1770\n",
      "Epoch 5/10\n",
      "4264/4263 [==============================] - 4318s - loss: 0.0843 - val_loss: 0.1566\n",
      "Epoch 6/10\n",
      "4264/4263 [==============================] - 4318s - loss: 0.0832 - val_loss: 0.1662\n",
      "Epoch 7/10\n",
      "4264/4263 [==============================] - 4321s - loss: 0.0822 - val_loss: 0.1997\n",
      "Epoch 8/10\n",
      "4264/4263 [==============================] - 4321s - loss: 0.0816 - val_loss: 0.2276\n",
      "Epoch 9/10\n",
      "4264/4263 [==============================] - 4320s - loss: 0.0808 - val_loss: 0.2216\n",
      "Epoch 10/10\n",
      "4264/4263 [==============================] - 4325s - loss: 0.0802 - val_loss: 0.1388\n"
     ]
    }
   ],
   "source": [
    "model.fit_generator(generator=trn_gen, steps_per_epoch=len(x_trn) / batch_size, epochs=10, verbose=1, \\\n",
    "                    validation_data=val_gen, validation_steps=len(x_val) / batch_size)\n",
    "\n",
    "model.save_weights(results_path+'nvidia1.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#filepath1 = results_path+'nvidia.h5'\n",
    "#checkpoint1 = ModelCheckpoint(filepath1, monitor='val_loss', verbose=1, save_best_only=False,\\\n",
    "#                             save_weights_only=True, mode='min', period=1)\n",
    "#callbacks1=[checkpoint1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "4264/4263 [==============================] - 4321s - loss: 0.0798 - val_loss: 0.2391\n",
      "Epoch 2/10\n",
      "4264/4263 [==============================] - 4322s - loss: 0.0790 - val_loss: 0.2149\n",
      "Epoch 3/10\n",
      "4264/4263 [==============================] - 4323s - loss: 0.0785 - val_loss: 0.2168\n",
      "Epoch 4/10\n",
      "4264/4263 [==============================] - 4324s - loss: 0.0779 - val_loss: 0.2222\n",
      "Epoch 5/10\n",
      "4264/4263 [==============================] - 4322s - loss: 0.0775 - val_loss: 0.2302\n",
      "Epoch 6/10\n",
      "4264/4263 [==============================] - 4320s - loss: 0.0771 - val_loss: 0.2397\n",
      "Epoch 7/10\n",
      "4264/4263 [==============================] - 4316s - loss: 0.0767 - val_loss: 0.2462\n",
      "Epoch 8/10\n",
      "4264/4263 [==============================] - 4312s - loss: 0.0763 - val_loss: 0.2498\n",
      "Epoch 9/10\n",
      "4264/4263 [==============================] - 4312s - loss: 0.0760 - val_loss: 0.2339\n",
      "Epoch 10/10\n",
      "4264/4263 [==============================] - 4326s - loss: 0.0757 - val_loss: 0.2360\n"
     ]
    }
   ],
   "source": [
    "model.optimizer.lr = 1e-5\n",
    "model.fit_generator(generator=trn_gen, steps_per_epoch=len(x_trn) / batch_size, epochs=10, verbose=1, \\\n",
    "                    validation_data=val_gen, validation_steps=len(x_val) / batch_size)\n",
    "\n",
    "model.save_weights(results_path+'nvidia2.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "4264/4263 [==============================] - 4326s - loss: 0.0757 - val_loss: 0.2519\n",
      "Epoch 2/10\n",
      "4264/4263 [==============================] - 5624s - loss: 0.0752 - val_loss: 0.2491\n",
      "Epoch 3/10\n",
      "4264/4263 [==============================] - 7588s - loss: 0.0749 - val_loss: 0.2420\n",
      "Epoch 4/10\n",
      "4264/4263 [==============================] - 8345s - loss: 0.0747 - val_loss: 0.2488\n",
      "Epoch 5/10\n",
      "4264/4263 [==============================] - 8202s - loss: 0.0745 - val_loss: 0.2523\n",
      "Epoch 6/10\n",
      "4264/4263 [==============================] - 6157s - loss: 0.0742 - val_loss: 0.2604\n",
      "Epoch 7/10\n",
      "4264/4263 [==============================] - 5637s - loss: 0.0742 - val_loss: 0.2607\n",
      "Epoch 8/10\n",
      "4264/4263 [==============================] - 5739s - loss: 0.0739 - val_loss: 0.2613\n",
      "Epoch 9/10\n",
      "4264/4263 [==============================] - 5654s - loss: 0.0738 - val_loss: 0.2611\n",
      "Epoch 10/10\n",
      "4264/4263 [==============================] - 5703s - loss: 0.0736 - val_loss: 0.2619\n"
     ]
    }
   ],
   "source": [
    "model.optimizer.lr = 1e-3\n",
    "model.fit_generator(generator=trn_gen, steps_per_epoch=len(x_trn) / batch_size, epochs=10, verbose=1, \\\n",
    "                    validation_data=val_gen, validation_steps=len(x_val) / batch_size)\n",
    "\n",
    "model.save_weights(results_path+'nvidia3.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#filepath2 = results_path+'nvidia_aug.h5'\n",
    "#checkpoint2 = ModelCheckpoint(filepath2, monitor='val_loss', verbose=1, save_best_only=False,\\\n",
    "#                             save_weights_only=True, mode='min', period=1)\n",
    "#callbacks2=[checkpoint2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "4264/4263 [==============================] - 5685s - loss: 0.0738 - val_loss: 0.2426\n",
      "Epoch 2/10\n",
      "4264/4263 [==============================] - 5671s - loss: 0.0733 - val_loss: 0.2488\n",
      "Epoch 3/10\n",
      "4264/4263 [==============================] - 5655s - loss: 0.0732 - val_loss: 0.2439\n",
      "Epoch 4/10\n",
      "4264/4263 [==============================] - 5703s - loss: 0.0730 - val_loss: 0.2423\n",
      "Epoch 5/10\n",
      "4264/4263 [==============================] - 5670s - loss: 0.0729 - val_loss: 0.2509\n",
      "Epoch 6/10\n",
      "4264/4263 [==============================] - 5671s - loss: 0.0727 - val_loss: 0.2506\n",
      "Epoch 7/10\n",
      "4264/4263 [==============================] - 5649s - loss: 0.0726 - val_loss: 0.2481\n",
      "Epoch 8/10\n",
      "4264/4263 [==============================] - 5663s - loss: 0.0725 - val_loss: 0.2528\n",
      "Epoch 9/10\n",
      "4264/4263 [==============================] - 5647s - loss: 0.0723 - val_loss: 0.2516\n",
      "Epoch 10/10\n",
      "4264/4263 [==============================] - 5679s - loss: 0.0721 - val_loss: 0.2576\n"
     ]
    }
   ],
   "source": [
    "model.optimizer.lr = 1e-5\n",
    "model.fit_generator(generator=trn_gen, steps_per_epoch=len(x_trn) / batch_size, epochs=10, verbose=1, \\\n",
    "                    validation_data=val_gen, validation_steps=len(x_val) / batch_size)\n",
    "\n",
    "model.save_weights(results_path+'nvidia4.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "4264/4263 [==============================] - 6357s - loss: 0.0723 - val_loss: 0.2281\n",
      "Epoch 2/10\n",
      "4264/4263 [==============================] - 34155s - loss: 0.0719 - val_loss: 0.2297\n",
      "Epoch 3/10\n",
      "4264/4263 [==============================] - 29895s - loss: 0.0719 - val_loss: 0.2322\n",
      "Epoch 4/10\n",
      "4264/4263 [==============================] - 8122s - loss: 0.0717 - val_loss: 0.2301\n",
      "Epoch 5/10\n",
      "4264/4263 [==============================] - 8109s - loss: 0.0716 - val_loss: 0.2304\n",
      "Epoch 6/10\n",
      "4264/4263 [==============================] - 8187s - loss: 0.0716 - val_loss: 0.2263\n",
      "Epoch 7/10\n",
      "4264/4263 [==============================] - 8165s - loss: 0.0715 - val_loss: 0.2392\n",
      "Epoch 8/10\n",
      "4264/4263 [==============================] - 8192s - loss: 0.0714 - val_loss: 0.2363\n",
      "Epoch 9/10\n",
      "4264/4263 [==============================] - 8175s - loss: 0.0713 - val_loss: 0.2334\n",
      "Epoch 10/10\n",
      "4264/4263 [==============================] - 8162s - loss: 0.0712 - val_loss: 0.2276\n"
     ]
    }
   ],
   "source": [
    "model.optimizer.lr = 1e-4\n",
    "model.fit_generator(generator=trn_gen, steps_per_epoch=len(x_trn) / batch_size, epochs=10, verbose=1, \\\n",
    "                    validation_data=val_gen, validation_steps=len(x_val) / batch_size)\n",
    "\n",
    "model.save_weights(results_path+'nvidia5.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "4264/4263 [==============================] - 5655s - loss: 0.0714 - val_loss: 0.2184\n",
      "Epoch 2/10\n",
      "4264/4263 [==============================] - 5445s - loss: 0.0711 - val_loss: 0.2192\n",
      "Epoch 3/10\n",
      "4264/4263 [==============================] - 4295s - loss: 0.0710 - val_loss: 0.2154\n",
      "Epoch 4/10\n",
      "4264/4263 [==============================] - 4295s - loss: 0.0708 - val_loss: 0.2165\n",
      "Epoch 5/10\n",
      "4264/4263 [==============================] - 4293s - loss: 0.0709 - val_loss: 0.2189\n",
      "Epoch 6/10\n",
      "4264/4263 [==============================] - 4304s - loss: 0.0708 - val_loss: 0.2138\n",
      "Epoch 7/10\n",
      "4264/4263 [==============================] - 7401s - loss: 0.0707 - val_loss: 0.2173\n",
      "Epoch 8/10\n",
      "4264/4263 [==============================] - 8149s - loss: 0.0707 - val_loss: 0.2172\n",
      "Epoch 9/10\n",
      "4264/4263 [==============================] - 8158s - loss: 0.0705 - val_loss: 0.2158\n",
      "Epoch 10/10\n",
      "4264/4263 [==============================] - 8169s - loss: 0.0705 - val_loss: 0.2194\n"
     ]
    }
   ],
   "source": [
    "model.optimizer.lr = 1e-5\n",
    "model.fit_generator(generator=trn_gen, steps_per_epoch=len(x_trn) / batch_size, epochs=10, verbose=1, \\\n",
    "                    validation_data=val_gen, validation_steps=len(x_val) / batch_size)\n",
    "\n",
    "model.save_weights(results_path+'nvidia6.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3 Nvidia All CONV model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lambda_4 (Lambda)            (None, 160, 320, 3)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_13 (Conv2D)           (None, 160, 320, 3)       12        \n",
      "_________________________________________________________________\n",
      "conv2d_14 (Conv2D)           (None, 160, 320, 24)      672       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_12 (MaxPooling (None, 80, 160, 24)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_15 (Conv2D)           (None, 80, 160, 36)       7812      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_13 (MaxPooling (None, 40, 80, 36)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_16 (Conv2D)           (None, 40, 80, 48)        15600     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_14 (MaxPooling (None, 20, 40, 48)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_17 (Conv2D)           (None, 20, 40, 64)        27712     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_15 (MaxPooling (None, 10, 20, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_18 (Conv2D)           (None, 10, 20, 128)       73856     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_16 (MaxPooling (None, 10, 5, 128)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_19 (Conv2D)           (None, 10, 5, 3)          3459      \n",
      "_________________________________________________________________\n",
      "global_average_pooling2d_1 ( (None, 3)                 0         \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 3)                 12        \n",
      "=================================================================\n",
      "Total params: 129,135\n",
      "Trainable params: 129,135\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = nvidia_conv()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model.compile(optimizer=\"adam\", loss=\"mse\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved model to disk\n"
     ]
    }
   ],
   "source": [
    "# serialize model to JSON\n",
    "model_path = results_path+'nvidia_conv.json'\n",
    "model_json = model.to_json()\n",
    "with open(model_path, \"w\") as json_file:\n",
    "    json_file.write(model_json)\n",
    "\n",
    "print(\"Saved model to disk\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "trn_gen = generate_batch(x_trn.shape[0], batch_size)\n",
    "val_gen = generate_batch(x_val.shape[0], batch_size, train=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "4264/4263 [==============================] - 4772s - loss: 0.0604 - val_loss: 0.3078\n",
      "Epoch 2/10\n",
      "4264/4263 [==============================] - 4734s - loss: 0.0611 - val_loss: 0.3096\n",
      "Epoch 3/10\n",
      "4264/4263 [==============================] - 4725s - loss: 0.0617 - val_loss: 0.3573\n",
      "Epoch 4/10\n",
      "4264/4263 [==============================] - 4723s - loss: 0.0627 - val_loss: 0.3523\n",
      "Epoch 5/10\n",
      "4264/4263 [==============================] - 4718s - loss: 0.0644 - val_loss: 0.3407\n",
      "Epoch 6/10\n",
      "4264/4263 [==============================] - 4731s - loss: 0.0635 - val_loss: 0.3497\n",
      "Epoch 7/10\n",
      "4264/4263 [==============================] - 4719s - loss: 0.0629 - val_loss: 0.3447\n",
      "Epoch 8/10\n",
      "4264/4263 [==============================] - 4892s - loss: 0.0628 - val_loss: 0.3542\n",
      "Epoch 9/10\n",
      "4264/4263 [==============================] - 7126s - loss: 0.0622 - val_loss: 0.3541\n",
      "Epoch 10/10\n",
      "4264/4263 [==============================] - 7093s - loss: 0.0621 - val_loss: 0.3466\n"
     ]
    }
   ],
   "source": [
    "model.fit_generator(generator=trn_gen, steps_per_epoch=len(x_trn) / batch_size, epochs=10, verbose=1, \\\n",
    "                    validation_data=val_gen, validation_steps=len(x_val) / batch_size)\n",
    "\n",
    "model.save_weights(results_path+'nvidia_conv1.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "4264/4263 [==============================] - 6892s - loss: 0.0627 - val_loss: 0.0604\n",
      "Epoch 2/10\n",
      "4264/4263 [==============================] - 6885s - loss: 0.0623 - val_loss: 0.1067\n",
      "Epoch 3/10\n",
      "4264/4263 [==============================] - 6909s - loss: 0.0627 - val_loss: 0.1158\n",
      "Epoch 4/10\n",
      "4264/4263 [==============================] - 6992s - loss: 0.0625 - val_loss: 0.0430\n",
      "Epoch 5/10\n",
      "4264/4263 [==============================] - 7058s - loss: 0.0625 - val_loss: 0.1184\n",
      "Epoch 6/10\n",
      "4264/4263 [==============================] - 7040s - loss: 0.0631 - val_loss: 0.1159\n",
      "Epoch 7/10\n",
      "4264/4263 [==============================] - 7060s - loss: 0.0621 - val_loss: 0.1190\n",
      "Epoch 8/10\n",
      "4264/4263 [==============================] - 7078s - loss: 0.0635 - val_loss: 0.1093\n",
      "Epoch 9/10\n",
      "4264/4263 [==============================] - 7072s - loss: 0.0632 - val_loss: 0.1007\n",
      "Epoch 10/10\n",
      "4264/4263 [==============================] - 7125s - loss: 0.0622 - val_loss: 0.1081\n"
     ]
    }
   ],
   "source": [
    "model.optimizer.lr = 1e-5\n",
    "model.fit_generator(generator=trn_gen, steps_per_epoch=len(x_trn) / batch_size, epochs=10, verbose=1, \\\n",
    "                    validation_data=val_gen, validation_steps=len(x_val) / batch_size)\n",
    "\n",
    "model.save_weights(results_path+'nvidia_conv2.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      " 132/4263 [..............................] - ETA: 7586s - loss: 0.0900"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-55-189b0bd04c4c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1e-3\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_generator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgenerator\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrn_gen\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_trn\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m                     \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mval_gen\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_val\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresults_path\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m'nvidia_conv3.h5'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/shreyas/anaconda3/envs/wheelai/lib/python3.5/site-packages/keras/legacy/interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     86\u001b[0m                 warnings.warn('Update your `' + object_name +\n\u001b[1;32m     87\u001b[0m                               '` call to the Keras 2 API: ' + signature, stacklevel=2)\n\u001b[0;32m---> 88\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     89\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_legacy_support_signature\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minspect\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetargspec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/shreyas/anaconda3/envs/wheelai/lib/python3.5/site-packages/keras/models.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_q_size, workers, pickle_safe, initial_epoch)\u001b[0m\n\u001b[1;32m   1105\u001b[0m                                         \u001b[0mworkers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1106\u001b[0m                                         \u001b[0mpickle_safe\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpickle_safe\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1107\u001b[0;31m                                         initial_epoch=initial_epoch)\n\u001b[0m\u001b[1;32m   1108\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1109\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0minterfaces\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegacy_generator_methods_support\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/shreyas/anaconda3/envs/wheelai/lib/python3.5/site-packages/keras/legacy/interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     86\u001b[0m                 warnings.warn('Update your `' + object_name +\n\u001b[1;32m     87\u001b[0m                               '` call to the Keras 2 API: ' + signature, stacklevel=2)\n\u001b[0;32m---> 88\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     89\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_legacy_support_signature\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minspect\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetargspec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/shreyas/anaconda3/envs/wheelai/lib/python3.5/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_q_size, workers, pickle_safe, initial_epoch)\u001b[0m\n\u001b[1;32m   1875\u001b[0m                     outs = self.train_on_batch(x, y,\n\u001b[1;32m   1876\u001b[0m                                                \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1877\u001b[0;31m                                                class_weight=class_weight)\n\u001b[0m\u001b[1;32m   1878\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1879\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/shreyas/anaconda3/envs/wheelai/lib/python3.5/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[0;34m(self, x, y, sample_weight, class_weight)\u001b[0m\n\u001b[1;32m   1619\u001b[0m             \u001b[0mins\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0msample_weights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1620\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_train_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1621\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1622\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1623\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/shreyas/anaconda3/envs/wheelai/lib/python3.5/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2101\u001b[0m         \u001b[0msession\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2102\u001b[0m         updated = session.run(self.outputs + [self.updates_op],\n\u001b[0;32m-> 2103\u001b[0;31m                               feed_dict=feed_dict)\n\u001b[0m\u001b[1;32m   2104\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mupdated\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2105\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/shreyas/anaconda3/envs/wheelai/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    765\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    766\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 767\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    768\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    769\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/shreyas/anaconda3/envs/wheelai/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    963\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    964\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m--> 965\u001b[0;31m                              feed_dict_string, options, run_metadata)\n\u001b[0m\u001b[1;32m    966\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    967\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/shreyas/anaconda3/envs/wheelai/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1013\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1014\u001b[0m       return self._do_call(_run_fn, self._session, feed_dict, fetch_list,\n\u001b[0;32m-> 1015\u001b[0;31m                            target_list, options, run_metadata)\n\u001b[0m\u001b[1;32m   1016\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1017\u001b[0m       return self._do_call(_prun_fn, self._session, handle, feed_dict,\n",
      "\u001b[0;32m/home/shreyas/anaconda3/envs/wheelai/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1020\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1021\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1022\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1023\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1024\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/shreyas/anaconda3/envs/wheelai/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1002\u001b[0m         return tf_session.TF_Run(session, options,\n\u001b[1;32m   1003\u001b[0m                                  \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1004\u001b[0;31m                                  status, run_metadata)\n\u001b[0m\u001b[1;32m   1005\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1006\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model.optimizer.lr = 1e-3\n",
    "model.fit_generator(generator=trn_gen, steps_per_epoch=len(x_trn) / batch_size, epochs=10, verbose=1, \\\n",
    "                    validation_data=val_gen, validation_steps=len(x_val) / batch_size)\n",
    "\n",
    "model.save_weights(results_path+'nvidia_conv3.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#filepath2 = results_path+'nvidia_aug.h5'\n",
    "#checkpoint2 = ModelCheckpoint(filepath2, monitor='val_loss', verbose=1, save_best_only=False,\\\n",
    "#                             save_weights_only=True, mode='min', period=1)\n",
    "#callbacks2=[checkpoint2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "   7/4263 [..............................] - ETA: 7907s - loss: 0.0880"
     ]
    }
   ],
   "source": [
    "model.optimizer.lr = 1e-5\n",
    "model.fit_generator(generator=trn_gen, steps_per_epoch=len(x_trn) / batch_size, epochs=10, verbose=1, \\\n",
    "                    validation_data=val_gen, validation_steps=len(x_val) / batch_size)\n",
    "\n",
    "model.save_weights(results_path+'nvidia_conv4.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model.optimizer.lr = 1e-4\n",
    "model.fit_generator(generator=trn_gen, steps_per_epoch=len(x_trn) / batch_size, epochs=10, verbose=1, \\\n",
    "                    validation_data=val_gen, validation_steps=len(x_val) / batch_size)\n",
    "\n",
    "model.save_weights(results_path+'nvidia_conv5.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model.optimizer.lr = 1e-5\n",
    "model.fit_generator(generator=trn_gen, steps_per_epoch=len(x_trn) / batch_size, epochs=10, verbose=1, \\\n",
    "                    validation_data=val_gen, validation_steps=len(x_val) / batch_size)\n",
    "\n",
    "model.save_weights(results_path+'nvidia_conv6.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
