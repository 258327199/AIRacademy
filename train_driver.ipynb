{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "CODE_DIR = '/home/shreyas/Documents/git/wheelai/'\n",
    "#DATA_DIR = '/media/shreyas/DATA/ML_DATA/wheelai/gtaV/'\n",
    "DATA_DIR = '/media/shreyas/DATA/ML_DATA/wheelai/gtaV/sample/'\n",
    "traindata_path = DATA_DIR + 'train/'\n",
    "validdata_path = '/media/shreyas/DATA/ML_DATA/wheelai/gtaV/valid/'\n",
    "results_path = '/media/shreyas/DATA/ML_DATA/wheelai/gtaV/results/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from __future__ import division, print_function\n",
    "\n",
    "import os, json\n",
    "from glob import glob\n",
    "import numpy as np\n",
    "from scipy import misc, ndimage\n",
    "from scipy.ndimage.interpolation import zoom\n",
    "\n",
    "import keras\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras import backend as K\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.models import Sequential, load_model,  Model\n",
    "from keras.layers.core import Flatten, Dense, Dropout, Lambda\n",
    "from keras.layers.convolutional import Conv2D, MaxPooling2D, ZeroPadding2D\n",
    "from keras.layers.pooling import GlobalAveragePooling2D\n",
    "from keras.optimizers import Adam, SGD\n",
    "from keras.preprocessing import image\n",
    "from keras.applications import VGG16\n",
    "from keras.layers import Lambda, Cropping2D\n",
    "\n",
    "%matplotlib inline\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Finetune and Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "epochs = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_batches(path, class_mode='categorical', gen=image.ImageDataGenerator(rescale=1./255), \\\n",
    "                shuffle=True, target_size=(224,224), batch_size=1):\n",
    "    return gen.flow_from_directory(path, class_mode=class_mode, batch_size=batch_size, \\\n",
    "                                   target_size=target_size, shuffle=shuffle)\n",
    "\n",
    "def get_steps(batches, batch_size):\n",
    "    steps = int(batches.samples/batch_size)\n",
    "    return (steps if batches.samples%batch_size==0 else (steps+1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 3006 images belonging to 3 classes.\n",
      "Found 554 images belonging to 3 classes.\n"
     ]
    }
   ],
   "source": [
    "train_b = get_batches(traindata_path, batch_size=batch_size)\n",
    "valid_b = get_batches(validdata_path, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_steps = get_steps(train_b, batch_size)\n",
    "valid_steps = get_steps(valid_b, batch_size)\n",
    "num_class = train_b.num_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_labels = train_b.classes\n",
    "valid_labels = valid_b.classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_train = keras.utils.to_categorical(train_labels)\n",
    "y_valid = keras.utils.to_categorical(valid_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3006,) (554,) (3006, 3) (554, 3)\n"
     ]
    }
   ],
   "source": [
    "print(train_labels.shape, valid_labels.shape, y_train.shape, y_valid.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 3006 images belonging to 3 classes.\n",
      "Found 554 images belonging to 3 classes.\n"
     ]
    }
   ],
   "source": [
    "trn_b = get_batches(traindata_path, class_mode=None, shuffle=False, batch_size=batch_size)\n",
    "val_b = get_batches(validdata_path, class_mode=None, shuffle=False, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 3006 images belonging to 3 classes.\n"
     ]
    }
   ],
   "source": [
    "gen_augdata = image.ImageDataGenerator(width_shift_range=.2, height_shift_range=.2, \n",
    "                                      shear_range=0.2, zoom_range=0.2)\n",
    "augtrain_b = get_batches(traindata_path, gen=gen_augdata, class_mode='categorical',\\\n",
    "                         batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def vgg_conv():\n",
    "    model = VGG16(include_top=False, weights='imagenet', input_shape=(122,224,3))\n",
    "    layers = model.layers\n",
    "    last_conv_idx = [index for index,layer in enumerate(layers) \n",
    "                     if type(layer) is Conv2D][-1]\n",
    "    conv_layers = layers[:15]\n",
    "    conv_model = Sequential(conv_layers)\n",
    "    model = Sequential()\n",
    "    model.add(Cropping2D(cropping=((73,29), (0,0)), input_shape=(224, 224, 3)))\n",
    "    model.add(conv_model)\n",
    "    return model\n",
    "\n",
    "\n",
    "def top_layer(input_shape):\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(512, (3,3), padding='same', activation='relu', input_shape=input_shape))\n",
    "    model.add(Dropout(0.1))\n",
    "    model.add(Conv2D(512, (3,3), padding='same', activation='relu'))\n",
    "    model.add(Dropout(0.1))\n",
    "    model.add(Conv2D(512, (3,3), padding='same', activation='relu'))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(MaxPooling2D(2,2))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(256, activation='elu'))\n",
    "    model.add(Dropout(0.3))\n",
    "    model.add(Dense(256, activation='elu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(num_class, activation='softmax'))\n",
    "    \n",
    "    return model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def basic_model(input_shape):\n",
    "    model = Sequential()\n",
    "    #model.add(BatchNormalization(axis=1, input_shape=input_shape))\n",
    "    model.add(Conv2D(32, (3,3), padding='same', activation='relu',input_shape=input_shape))\n",
    "    model.add(Conv2D(32, (3,3), padding='same', activation='relu'))\n",
    "    model.add(Conv2D(32, (3,3), padding='same', activation='relu'))\n",
    "    model.add(Flatten())    \n",
    "    model.add(Dense(256, activation='relu'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dense(256, activation='relu'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dense(3, activation='softmax'))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_ft(trn_b, train_steps, val_b, valid_steps):\n",
    "    model = vgg_conv()\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "    trn_ft = model.predict_generator(trn_b, train_steps)\n",
    "    val_ft = model.predict_generator(val_b, valid_steps)\n",
    "    print(trn_ft.shape, val_ft.shape)\n",
    "\n",
    "    np.save(results_path + 'trn_ft.npy', trn_ft)\n",
    "    np.save(results_path + 'val_ft.npy', val_ft)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3006, 7, 14, 512) (554, 7, 14, 512)\n"
     ]
    }
   ],
   "source": [
    "get_ft(trn_b, train_steps, val_b, valid_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train = np.load(results_path + 'trn_ft.npy')\n",
    "X_valid = np.load(results_path + 'val_ft.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = top_layer(X_train.shape[1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy', optimizer=Adam(lr=2e-5), metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#vgg_model.fit(X_train, y_train, epochs=2, batch_size=1, verbose=1, \\\n",
    "#          validation_data=(X_valid, y_valid))\n",
    "#vgg_model.fit_generator(train_b, steps_per_epoch=train_steps, epochs=10,\\\n",
    "#                   validation_data=valid_b, validation_steps=valid_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#model.save_weights(results_path+'trial_bottleneck.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "filepath1 = results_path+'vgg_bottleneck.h5'\n",
    "checkpoint1 = ModelCheckpoint(filepath1, monitor='val_loss', verbose=1, save_best_only=True,\\\n",
    "                             save_weights_only=True, mode='min', period=1)\n",
    "callbacks1=[checkpoint1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 3006 samples, validate on 554 samples\n",
      "Epoch 1/21\n",
      "3004/3006 [============================>.] - ETA: 0s - loss: 0.4813 - acc: 0.8006Epoch 00000: val_loss improved from 0.57303 to 0.53099, saving model to /media/shreyas/DATA/ML_DATA/wheelai/gtaV/results/vgg_bottleneck.h5\n",
      "3006/3006 [==============================] - 52s - loss: 0.4812 - acc: 0.8007 - val_loss: 0.5310 - val_acc: 0.7690\n",
      "Epoch 2/21\n",
      "3003/3006 [============================>.] - ETA: 0s - loss: 0.3740 - acc: 0.8598Epoch 00001: val_loss improved from 0.53099 to 0.51487, saving model to /media/shreyas/DATA/ML_DATA/wheelai/gtaV/results/vgg_bottleneck.h5\n",
      "3006/3006 [==============================] - 52s - loss: 0.3739 - acc: 0.8599 - val_loss: 0.5149 - val_acc: 0.8014\n",
      "Epoch 3/21\n",
      "3002/3006 [============================>.] - ETA: 0s - loss: 0.2713 - acc: 0.8894Epoch 00002: val_loss improved from 0.51487 to 0.48343, saving model to /media/shreyas/DATA/ML_DATA/wheelai/gtaV/results/vgg_bottleneck.h5\n",
      "3006/3006 [==============================] - 53s - loss: 0.2715 - acc: 0.8892 - val_loss: 0.4834 - val_acc: 0.8087\n",
      "Epoch 4/21\n",
      "3004/3006 [============================>.] - ETA: 0s - loss: 0.2087 - acc: 0.9248Epoch 00003: val_loss did not improve\n",
      "3006/3006 [==============================] - 52s - loss: 0.2090 - acc: 0.9248 - val_loss: 0.5115 - val_acc: 0.8051\n",
      "Epoch 5/21\n",
      "3003/3006 [============================>.] - ETA: 0s - loss: 0.1636 - acc: 0.9397Epoch 00004: val_loss improved from 0.48343 to 0.46983, saving model to /media/shreyas/DATA/ML_DATA/wheelai/gtaV/results/vgg_bottleneck.h5\n",
      "3006/3006 [==============================] - 53s - loss: 0.1635 - acc: 0.9398 - val_loss: 0.4698 - val_acc: 0.8249\n",
      "Epoch 6/21\n",
      "3005/3006 [============================>.] - ETA: 0s - loss: 0.1219 - acc: 0.9571Epoch 00005: val_loss did not improve\n",
      "3006/3006 [==============================] - 53s - loss: 0.1219 - acc: 0.9571 - val_loss: 0.5961 - val_acc: 0.7942\n",
      "Epoch 7/21\n",
      "3004/3006 [============================>.] - ETA: 0s - loss: 0.1123 - acc: 0.9611Epoch 00006: val_loss did not improve\n",
      "3006/3006 [==============================] - 52s - loss: 0.1122 - acc: 0.9611 - val_loss: 0.6004 - val_acc: 0.7906\n",
      "Epoch 8/21\n",
      "3003/3006 [============================>.] - ETA: 0s - loss: 0.0801 - acc: 0.9764Epoch 00007: val_loss did not improve\n",
      "3006/3006 [==============================] - 52s - loss: 0.0800 - acc: 0.9764 - val_loss: 0.7442 - val_acc: 0.7906\n",
      "Epoch 9/21\n",
      "3004/3006 [============================>.] - ETA: 0s - loss: 0.0795 - acc: 0.9717Epoch 00008: val_loss did not improve\n",
      "3006/3006 [==============================] - 52s - loss: 0.0794 - acc: 0.9717 - val_loss: 0.6394 - val_acc: 0.8303\n",
      "Epoch 10/21\n",
      "3003/3006 [============================>.] - ETA: 0s - loss: 0.0732 - acc: 0.9770Epoch 00009: val_loss did not improve\n",
      "3006/3006 [==============================] - 52s - loss: 0.0732 - acc: 0.9770 - val_loss: 0.7982 - val_acc: 0.8087\n",
      "Epoch 11/21\n",
      "3003/3006 [============================>.] - ETA: 0s - loss: 0.0622 - acc: 0.9797Epoch 00010: val_loss did not improve\n",
      "3006/3006 [==============================] - 53s - loss: 0.0621 - acc: 0.9797 - val_loss: 0.6744 - val_acc: 0.8321\n",
      "Epoch 12/21\n",
      "3004/3006 [============================>.] - ETA: 0s - loss: 0.0683 - acc: 0.9774Epoch 00011: val_loss did not improve\n",
      "3006/3006 [==============================] - 53s - loss: 0.0682 - acc: 0.9774 - val_loss: 0.8868 - val_acc: 0.8087\n",
      "Epoch 13/21\n",
      "3005/3006 [============================>.] - ETA: 0s - loss: 0.0532 - acc: 0.9830Epoch 00012: val_loss did not improve\n",
      "3006/3006 [==============================] - 52s - loss: 0.0532 - acc: 0.9830 - val_loss: 0.9651 - val_acc: 0.7906\n",
      "Epoch 14/21\n",
      "3004/3006 [============================>.] - ETA: 0s - loss: 0.0620 - acc: 0.9810Epoch 00013: val_loss did not improve\n",
      "3006/3006 [==============================] - 53s - loss: 0.0619 - acc: 0.9810 - val_loss: 0.8625 - val_acc: 0.8213\n",
      "Epoch 15/21\n",
      "3005/3006 [============================>.] - ETA: 0s - loss: 0.0650 - acc: 0.9794Epoch 00014: val_loss did not improve\n",
      "3006/3006 [==============================] - 53s - loss: 0.0650 - acc: 0.9794 - val_loss: 0.8124 - val_acc: 0.8249\n",
      "Epoch 16/21\n",
      "3003/3006 [============================>.] - ETA: 0s - loss: 0.0423 - acc: 0.9860Epoch 00015: val_loss did not improve\n",
      "3006/3006 [==============================] - 53s - loss: 0.0431 - acc: 0.9857 - val_loss: 0.9446 - val_acc: 0.8105\n",
      "Epoch 17/21\n",
      "3003/3006 [============================>.] - ETA: 0s - loss: 0.0366 - acc: 0.9880Epoch 00016: val_loss did not improve\n",
      "3006/3006 [==============================] - 53s - loss: 0.0365 - acc: 0.9880 - val_loss: 0.8758 - val_acc: 0.8267\n",
      "Epoch 18/21\n",
      "3005/3006 [============================>.] - ETA: 0s - loss: 0.0518 - acc: 0.9857Epoch 00017: val_loss did not improve\n",
      "3006/3006 [==============================] - 53s - loss: 0.0518 - acc: 0.9857 - val_loss: 0.8158 - val_acc: 0.8484\n",
      "Epoch 19/21\n",
      "3005/3006 [============================>.] - ETA: 0s - loss: 0.0477 - acc: 0.9867Epoch 00018: val_loss did not improve\n",
      "3006/3006 [==============================] - 53s - loss: 0.0477 - acc: 0.9867 - val_loss: 0.7919 - val_acc: 0.8430\n",
      "Epoch 20/21\n",
      "3005/3006 [============================>.] - ETA: 0s - loss: 0.0429 - acc: 0.9877Epoch 00019: val_loss did not improve\n",
      "3006/3006 [==============================] - 53s - loss: 0.0429 - acc: 0.9877 - val_loss: 1.1089 - val_acc: 0.8087\n",
      "Epoch 21/21\n",
      "3004/3006 [============================>.] - ETA: 0s - loss: 0.0520 - acc: 0.9857Epoch 00020: val_loss did not improve\n",
      "3006/3006 [==============================] - 52s - loss: 0.0520 - acc: 0.9857 - val_loss: 0.9415 - val_acc: 0.8357\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f7996564ac8>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train, epochs=21, batch_size=1, verbose=1, \\\n",
    "          callbacks=callbacks1, validation_data=(X_valid, y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def vgg_model():\n",
    "    base_model = vgg_conv()\n",
    "    for layer in base_model.layers[:11]: layer.trainable=False\n",
    "    print (base_model.output_shape[1:])\n",
    "    top_model = top_layer(base_model.output_shape[1:])\n",
    "    top_model.load_weights(results_path+'vgg_bottleneck.h5')\n",
    "    \n",
    "    base_model.add(top_model)\n",
    "    \n",
    "    return base_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7, 14, 512)\n"
     ]
    }
   ],
   "source": [
    "vgg_model = vgg_model()\n",
    "vgg_model.compile(loss='categorical_crossentropy', optimizer=SGD(lr=2e-5, momentum=0.9), metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "filepath2 = results_path+'vgg_ft.h5'\n",
    "checkpoint2 = ModelCheckpoint(filepath2, monitor='val_loss', verbose=1,\\\n",
    "                              save_best_only=True, mode='min', period=1)\n",
    "callbacks2=[checkpoint2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/21\n",
      "93/94 [============================>.] - ETA: 0s - loss: 0.0908 - acc: 0.9701Epoch 00000: val_loss improved from inf to 0.46169, saving model to /media/shreyas/DATA/ML_DATA/wheelai/gtaV/results/vgg_ft.h5\n",
      "94/94 [==============================] - 50s - loss: 0.0905 - acc: 0.9704 - val_loss: 0.4617 - val_acc: 0.8303\n",
      "Epoch 2/21\n",
      "93/94 [============================>.] - ETA: 0s - loss: 0.0721 - acc: 0.9795Epoch 00001: val_loss improved from 0.46169 to 0.46043, saving model to /media/shreyas/DATA/ML_DATA/wheelai/gtaV/results/vgg_ft.h5\n",
      "94/94 [==============================] - 45s - loss: 0.0723 - acc: 0.9790 - val_loss: 0.4604 - val_acc: 0.8285\n",
      "Epoch 3/21\n",
      "93/94 [============================>.] - ETA: 0s - loss: 0.0685 - acc: 0.9792Epoch 00002: val_loss did not improve\n",
      "94/94 [==============================] - 44s - loss: 0.0690 - acc: 0.9790 - val_loss: 0.4797 - val_acc: 0.8177\n",
      "Epoch 4/21\n",
      "93/94 [============================>.] - ETA: 0s - loss: 0.0630 - acc: 0.9849Epoch 00003: val_loss did not improve\n",
      "94/94 [==============================] - 44s - loss: 0.0637 - acc: 0.9843 - val_loss: 0.4690 - val_acc: 0.8267\n",
      "Epoch 5/21\n",
      "93/94 [============================>.] - ETA: 0s - loss: 0.0632 - acc: 0.9812Epoch 00004: val_loss improved from 0.46043 to 0.41520, saving model to /media/shreyas/DATA/ML_DATA/wheelai/gtaV/results/vgg_ft.h5\n",
      "94/94 [==============================] - 45s - loss: 0.0630 - acc: 0.9814 - val_loss: 0.4152 - val_acc: 0.8448\n",
      "Epoch 6/21\n",
      "93/94 [============================>.] - ETA: 0s - loss: 0.0613 - acc: 0.9822Epoch 00005: val_loss improved from 0.41520 to 0.41342, saving model to /media/shreyas/DATA/ML_DATA/wheelai/gtaV/results/vgg_ft.h5\n",
      "94/94 [==============================] - 45s - loss: 0.0611 - acc: 0.9824 - val_loss: 0.4134 - val_acc: 0.8357\n",
      "Epoch 7/21\n",
      "93/94 [============================>.] - ETA: 0s - loss: 0.0560 - acc: 0.9862Epoch 00006: val_loss did not improve\n",
      "94/94 [==============================] - 44s - loss: 0.0558 - acc: 0.9864 - val_loss: 0.5112 - val_acc: 0.8177\n",
      "Epoch 8/21\n",
      "93/94 [============================>.] - ETA: 0s - loss: 0.0546 - acc: 0.9842Epoch 00007: val_loss improved from 0.41342 to 0.40920, saving model to /media/shreyas/DATA/ML_DATA/wheelai/gtaV/results/vgg_ft.h5\n",
      "94/94 [==============================] - 45s - loss: 0.0543 - acc: 0.9844 - val_loss: 0.4092 - val_acc: 0.8285\n",
      "Epoch 9/21\n",
      "93/94 [============================>.] - ETA: 0s - loss: 0.0526 - acc: 0.9852Epoch 00008: val_loss did not improve\n",
      "94/94 [==============================] - 44s - loss: 0.0523 - acc: 0.9854 - val_loss: 0.4665 - val_acc: 0.8357\n",
      "Epoch 10/21\n",
      "93/94 [============================>.] - ETA: 0s - loss: 0.0481 - acc: 0.9886Epoch 00009: val_loss did not improve\n",
      "94/94 [==============================] - 45s - loss: 0.0482 - acc: 0.9883 - val_loss: 0.4114 - val_acc: 0.8412\n",
      "Epoch 11/21\n",
      "93/94 [============================>.] - ETA: 0s - loss: 0.0487 - acc: 0.9866Epoch 00010: val_loss did not improve\n",
      "94/94 [==============================] - 44s - loss: 0.0493 - acc: 0.9863 - val_loss: 0.4602 - val_acc: 0.8195\n",
      "Epoch 12/21\n",
      "93/94 [============================>.] - ETA: 0s - loss: 0.0471 - acc: 0.9859Epoch 00011: val_loss did not improve\n",
      "94/94 [==============================] - 44s - loss: 0.0468 - acc: 0.9860 - val_loss: 0.4238 - val_acc: 0.8321\n",
      "Epoch 13/21\n",
      "93/94 [============================>.] - ETA: 0s - loss: 0.0439 - acc: 0.9889Epoch 00012: val_loss did not improve\n",
      "94/94 [==============================] - 44s - loss: 0.0442 - acc: 0.9887 - val_loss: 0.4433 - val_acc: 0.8556\n",
      "Epoch 14/21\n",
      "93/94 [============================>.] - ETA: 0s - loss: 0.0436 - acc: 0.9882Epoch 00013: val_loss did not improve\n",
      "94/94 [==============================] - 44s - loss: 0.0441 - acc: 0.9880 - val_loss: 0.4621 - val_acc: 0.8267\n",
      "Epoch 15/21\n",
      "93/94 [============================>.] - ETA: 0s - loss: 0.0445 - acc: 0.9872Epoch 00014: val_loss did not improve\n",
      "94/94 [==============================] - 44s - loss: 0.0445 - acc: 0.9874 - val_loss: 0.4826 - val_acc: 0.8303\n",
      "Epoch 16/21\n",
      "93/94 [============================>.] - ETA: 0s - loss: 0.0417 - acc: 0.9896Epoch 00015: val_loss did not improve\n",
      "94/94 [==============================] - 44s - loss: 0.0415 - acc: 0.9897 - val_loss: 0.4252 - val_acc: 0.8448\n",
      "Epoch 17/21\n",
      "93/94 [============================>.] - ETA: 0s - loss: 0.0470 - acc: 0.9869Epoch 00016: val_loss did not improve\n",
      "94/94 [==============================] - 44s - loss: 0.0466 - acc: 0.9870 - val_loss: 0.4916 - val_acc: 0.8249\n",
      "Epoch 18/21\n",
      "93/94 [============================>.] - ETA: 0s - loss: 0.0408 - acc: 0.9892Epoch 00017: val_loss did not improve\n",
      "94/94 [==============================] - 44s - loss: 0.0406 - acc: 0.9894 - val_loss: 0.4373 - val_acc: 0.8412\n",
      "Epoch 19/21\n",
      "93/94 [============================>.] - ETA: 0s - loss: 0.0413 - acc: 0.9886Epoch 00018: val_loss did not improve\n",
      "94/94 [==============================] - 44s - loss: 0.0412 - acc: 0.9887 - val_loss: 0.4550 - val_acc: 0.8339\n",
      "Epoch 20/21\n",
      "93/94 [============================>.] - ETA: 0s - loss: 0.0393 - acc: 0.9882Epoch 00019: val_loss did not improve\n",
      "94/94 [==============================] - 45s - loss: 0.0392 - acc: 0.9880 - val_loss: 0.4489 - val_acc: 0.8375\n",
      "Epoch 21/21\n",
      "93/94 [============================>.] - ETA: 0s - loss: 0.0381 - acc: 0.9916Epoch 00020: val_loss did not improve\n",
      "94/94 [==============================] - 44s - loss: 0.0378 - acc: 0.9917 - val_loss: 0.4399 - val_acc: 0.8357\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f79807b4da0>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vgg_model.fit_generator(train_b, steps_per_epoch=train_steps, epochs=21, callbacks=callbacks2,\\\n",
    "                        validation_data=valid_b, validation_steps=valid_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "filepath3 = results_path+'vgg_augmented_ft.h5'\n",
    "checkpoint3 = ModelCheckpoint(filepath3, monitor='val_loss', verbose=1,\\\n",
    "                              save_best_only=True, mode='min', period=1)\n",
    "callbacks3=[checkpoint3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/13\n",
      "93/94 [============================>.] - ETA: 0s - loss: 7.5173 - acc: 0.5178Epoch 00000: val_loss improved from inf to 0.50424, saving model to /media/shreyas/DATA/ML_DATA/wheelai/gtaV/results/vgg_augmented_ft.h5\n",
      "94/94 [==============================] - 62s - loss: 7.5185 - acc: 0.5173 - val_loss: 0.5042 - val_acc: 0.8177\n",
      "Epoch 2/13\n",
      "93/94 [============================>.] - ETA: 0s - loss: 7.1748 - acc: 0.5312Epoch 00001: val_loss did not improve\n",
      "94/94 [==============================] - 56s - loss: 7.1695 - acc: 0.5313 - val_loss: 0.6675 - val_acc: 0.7708\n",
      "Epoch 3/13\n",
      "93/94 [============================>.] - ETA: 0s - loss: 6.9595 - acc: 0.5427Epoch 00002: val_loss did not improve\n",
      "94/94 [==============================] - 55s - loss: 6.9550 - acc: 0.5429 - val_loss: 0.5594 - val_acc: 0.7906\n",
      "Epoch 4/13\n",
      "93/94 [============================>.] - ETA: 0s - loss: 6.4580 - acc: 0.5625Epoch 00003: val_loss did not improve\n",
      "94/94 [==============================] - 55s - loss: 6.4661 - acc: 0.5622 - val_loss: 0.6848 - val_acc: 0.7401\n",
      "Epoch 5/13\n",
      "93/94 [============================>.] - ETA: 0s - loss: 6.4814 - acc: 0.5662Epoch 00004: val_loss did not improve\n",
      "94/94 [==============================] - 55s - loss: 6.4599 - acc: 0.5673 - val_loss: 0.5704 - val_acc: 0.7798\n",
      "Epoch 6/13\n",
      "93/94 [============================>.] - ETA: 0s - loss: 5.9405 - acc: 0.5917Epoch 00005: val_loss did not improve\n",
      "94/94 [==============================] - 56s - loss: 5.9460 - acc: 0.5915 - val_loss: 0.5133 - val_acc: 0.7888\n",
      "Epoch 7/13\n",
      "93/94 [============================>.] - ETA: 0s - loss: 5.4931 - acc: 0.6055Epoch 00006: val_loss improved from 0.50424 to 0.46896, saving model to /media/shreyas/DATA/ML_DATA/wheelai/gtaV/results/vgg_augmented_ft.h5\n",
      "94/94 [==============================] - 57s - loss: 5.5015 - acc: 0.6047 - val_loss: 0.4690 - val_acc: 0.7834\n",
      "Epoch 8/13\n",
      "93/94 [============================>.] - ETA: 0s - loss: 5.3756 - acc: 0.5995Epoch 00007: val_loss did not improve\n",
      "94/94 [==============================] - 56s - loss: 5.3650 - acc: 0.5998 - val_loss: 0.5514 - val_acc: 0.7726\n",
      "Epoch 9/13\n",
      "93/94 [============================>.] - ETA: 0s - loss: 4.6010 - acc: 0.6183Epoch 00008: val_loss did not improve\n",
      "94/94 [==============================] - 56s - loss: 4.6101 - acc: 0.6167 - val_loss: 0.5396 - val_acc: 0.7906\n",
      "Epoch 10/13\n",
      "93/94 [============================>.] - ETA: 0s - loss: 3.2260 - acc: 0.6048Epoch 00009: val_loss did not improve\n",
      "94/94 [==============================] - 55s - loss: 3.2165 - acc: 0.6048 - val_loss: 0.7440 - val_acc: 0.7852\n",
      "Epoch 11/13\n",
      "93/94 [============================>.] - ETA: 0s - loss: 2.1335 - acc: 0.5870Epoch 00010: val_loss did not improve\n",
      "94/94 [==============================] - 55s - loss: 2.1289 - acc: 0.5868 - val_loss: 0.8438 - val_acc: 0.7473\n",
      "Epoch 12/13\n",
      "93/94 [============================>.] - ETA: 0s - loss: 1.6867 - acc: 0.5746Epoch 00011: val_loss did not improve\n",
      "94/94 [==============================] - 55s - loss: 1.6928 - acc: 0.5745 - val_loss: 0.8895 - val_acc: 0.7202\n",
      "Epoch 13/13\n",
      "93/94 [============================>.] - ETA: 0s - loss: 1.5125 - acc: 0.5554Epoch 00012: val_loss did not improve\n",
      "94/94 [==============================] - 55s - loss: 1.5127 - acc: 0.5556 - val_loss: 0.9236 - val_acc: 0.7347\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f799653ef60>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vgg_model.fit_generator(augtrain_b, steps_per_epoch=train_steps, epochs=13, callbacks=callbacks3,\\\n",
    "                        validation_data=valid_b, validation_steps=valid_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.save_weights(results_path+'vgg_ft_augmenteddata.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "preds.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print (preds[:5])\n",
    "img = batches.filenames\n",
    "print (img[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "Image.open(DATA_DIR+'test/'+img[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "save_array(results_path + 'test_predictions.dat', preds)\n",
    "save_array(results_path + 'imagefiles.dat', img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Validate Predictions\n",
    "Lets plot -\n",
    "1. A few correct labels at random\n",
    "2. A few incorrect labels at random\n",
    "3. Most confident correct predictions of each class\n",
    "4. Most confident incorrect predictions of each class\n",
    "5. Most uncertain labels (probabilites close to 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vgg.model.load_weights(filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "val_batches, probs = vgg.test(validdata_path, batch_size=batch_size*2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "img = val_batches.filenames\n",
    "expected_labels = val_batches.classes\n",
    "\n",
    "our_predictions = probs[:,0]\n",
    "other_predictions = np.round(probs[:,1])\n",
    "our_labels = np.round(1-our_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.preprocessing import image\n",
    "\n",
    "def plots_idx(idx, titles=None):\n",
    "    plots([image.load_img(validdata_path + img[i]) for i in idx], titles=titles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n_view = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "correct = np.where(our_labels==expected_labels)[0]\n",
    "print (\"Found %d correct labels\" % len(correct))\n",
    "idx = permutation(correct)[:n_view]\n",
    "plots_idx(idx, our_predictions[idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "incorrect = np.where(our_labels!=expected_labels)[0]\n",
    "print (\"Found %d incorrect labels\" % len(incorrect))\n",
    "idx = permutation(incorrect)[:n_view]\n",
    "plots_idx(idx, our_predictions[idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "#3a. The images we most confident were cats, and are actually cats\n",
    "correct_cats = np.where((our_labels==0) & (our_labels==expected_labels))[0]\n",
    "print (\"Found %d confident correct cats labels\" % len(correct_cats))\n",
    "most_correct_cats = np.argsort(our_predictions[correct_cats])[::-1][:n_view]\n",
    "plots_idx(correct_cats[most_correct_cats], our_predictions[correct_cats][most_correct_cats])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#3b. The images we most confident were dogs, and are actually dogs\n",
    "correct_dogs = np.where((our_labels==1) & (our_labels==expected_labels))[0]\n",
    "print (\"Found %d confident correct dogs labels\" % len(correct_dogs))\n",
    "most_correct_dogs = np.argsort(our_predictions[correct_dogs])[:n_view]\n",
    "plots_idx(correct_dogs[most_correct_dogs], our_predictions[correct_dogs][most_correct_dogs])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#4a. The images we were most confident were cats, but are actually dogs\n",
    "incorrect_cats = np.where((our_labels==0) & (our_labels!=expected_labels))[0]\n",
    "print (\"Found %d incorrect cats\" % len(incorrect_cats))\n",
    "if len(incorrect_cats):\n",
    "    most_incorrect_cats = np.argsort(our_predictions[incorrect_cats])[::-1][:n_view]\n",
    "    plots_idx(incorrect_cats[most_incorrect_cats], our_predictions[incorrect_cats][most_incorrect_cats])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#4b. The images we were most confident were dogs, but are actually cats\n",
    "incorrect_dogs = np.where((our_labels==1) & (our_labels!=expected_labels))[0]\n",
    "print (\"Found %d incorrect dogs\" % len(incorrect_dogs))\n",
    "if len(incorrect_dogs):\n",
    "    most_incorrect_dogs = np.argsort(our_predictions[incorrect_dogs])[:n_view]\n",
    "    plots_idx(incorrect_dogs[most_incorrect_dogs], our_predictions[incorrect_dogs][most_incorrect_dogs])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#5. The most uncertain labels (ie those with probability closest to 0.5).\n",
    "most_uncertain = np.argsort(np.abs(our_predictions-0.5))\n",
    "plots_idx(most_uncertain[:n_view], our_predictions[most_uncertain])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "cm = confusion_matrix(expected_labels, our_labels)\n",
    "plot_confusion_matrix(cm, val_batches.class_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "preds = load_array(results_path + 'test_predictions.dat')\n",
    "filenames = load_array(results_path + 'imagefiles.dat')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "isdog = preds[:,1]\n",
    "print (\"Raw Predictions: \"+ str(isdog[:5]))\n",
    "print (\"Mid Predictions: \"+str(isdog[(isdog<.6)&(isdog>0.4)]))\n",
    "print (\"Edge Predictions: \"+str(isdog[(isdog<0.02)&(isdog>.98)]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.amax(isdog)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Extract imageIds from the filenames in our test/unknown directory \n",
    "filenames = batches.filenames\n",
    "ids = np.array([int(f[8:f.find('.')]) for f in filenames])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "subm = np.stack([ids,isdog], axis=1)\n",
    "subm[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%cd $DATA_DIR\n",
    "submission_file_name = 'submission1.csv'\n",
    "np.savetxt(submission_file_name, subm, fmt='%d,%.5f', header='id,label', comments='')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
